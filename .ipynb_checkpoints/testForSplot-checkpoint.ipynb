{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision import transforms, utils\n",
    "import os\n",
    "import datetime \n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "##文件数据行为: x   y   z  time     ；表示一个坐标点的三个坐标分量和 采集时间 ，使用空格符分隔\n",
    "\n",
    "def pre(source, distance, diantance1):\n",
    "    f = open(source, \"r\")  # 源文件\n",
    "    fwrit = open(distance, \"a\")  # 卡2068\n",
    "    for s in f.readlines():\n",
    "        if len(s) == 1:\n",
    "            fwrit.write(s)\n",
    "        else:\n",
    "            s = s[:-1]\n",
    "            tem = s.split()\n",
    "            re = tem[1].split(':')[1] + \"\\t\" + tem[2].split(':')[1] + \"\\t\" + tem[3].split(':')[1] + \"\\t\" + tem[-2] + \"\\t\" + tem[-1] + \"\\n\"\n",
    "            # if tem[0] != \"2068\":\n",
    "            #     fwrit1.write(re)\n",
    "            # else:\n",
    "            if tem[0] == \"2068\":\n",
    "                fwrit.write(re)\n",
    "    f.close()\n",
    "    fwrit.close()\n",
    "\n",
    "\n",
    "def file_name(file_dir, target, target1):\n",
    "    path = [file_dir + '\\\\' + x for x in os.listdir(file_dir)]\n",
    "    for p in path:\n",
    "        if not os.path.isdir(p):\n",
    "            pre(p, target, target1)\n",
    "\n",
    "def split_data(splot):\n",
    "    \"\"\"\n",
    "    按照plot划分时间段\n",
    "    \"\"\"\n",
    "    state = \"D:\\\\fig\\\\data\\\\pre2068Static.txt\"\n",
    "    unrealize = \"D:\\\\fig\\\\data\\\\pre2068Unrealize.txt\"\n",
    "    Sactive = \"D:\\\\fig\\\\data\\\\pre2068Little.txt\"\n",
    "    Mactive = \"D:\\\\fig\\\\data\\\\pre2068LargeMove.txt\"\n",
    "    files = [state, unrealize, Sactive, Mactive]\n",
    "    mask = [0., 1., 2., 3.]\n",
    "    splotre = []\n",
    "    lable = [] \n",
    "    for index, file in enumerate(files):\n",
    "        f = open(file, \"r\")\n",
    "        mk = mask[index]\n",
    "\n",
    "        flag = False \n",
    "        start = ''\n",
    "        obj = [] \n",
    "        for s in f.readlines():\n",
    "            if len(s) <= 1:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                s = s[:-1]\n",
    "                seq = s.split(\"\\t\")\n",
    "                if flag == False :\n",
    "                    #本数据序列第一点的采集时间\n",
    "                    start = 0\n",
    "                    now = 0\n",
    "                    flag = True \n",
    "                # 当前点的采集时间\n",
    "                now = now + 1\n",
    "                subt = now - start \n",
    "                obj.append(np.asarray(seq[:3],dtype='float64'))\n",
    "            if subt > splot:\n",
    "                splotre.append(np.asarray(obj))\n",
    "                lable.append(mk)\n",
    "                obj.clear() \n",
    "                flag = False\n",
    "    splotre = np.asarray(splotre)\n",
    "    lable = np.asarray(lable)\n",
    "    return splotre, lable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大幅度运动 原始数据源\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\active\"\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068LargeMove.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preLargeMove.txt\"  # 其他卡的处理结果\n",
    "\n",
    "file_name(p, t, t1)\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\little\"  # 原始数据源\n",
    "\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Little.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preLittle.txt\"  # 其他卡的处理结果\n",
    "\n",
    "file_name(p, t, t1)\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\static\"  # 原始数据源\n",
    "\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Static.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preStatic.txt\"  # 其他卡的处理结果\n",
    "file_name(p, t, t1)\n",
    "# 无意识运动，如转身，手摆动\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\unrealize\"  # 原始数据源\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Unrealize.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preUnrealize.txt\"  # 其他卡的处理结果径\n",
    "file_name(p, t, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "splotre, lable = split_data(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114538, 10, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splotre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114538,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 25000\n",
    "index = list(range(splotre.shape[0]))\n",
    "np.random.shuffle(index)\n",
    "splotre = splotre[index]\n",
    "lable = lable[index]\n",
    "train_splot = splotre[:NUM_TRAIN-1000]\n",
    "train_lable = lable[:NUM_TRAIN-1000]\n",
    "val_splot = splotre[NUM_TRAIN-1000:NUM_TRAIN]\n",
    "val_lable = lable[NUM_TRAIN-1000:NUM_TRAIN]\n",
    "test_splot = splotre[NUM_TRAIN:]\n",
    "test_lable = lable[NUM_TRAIN:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, splot):\n",
    "        return torch.from_numpy(splot)\n",
    "    \n",
    "trans = T.Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "class LocationDataset(Dataset):\n",
    "    def __init__(self, splotre, lable, transform = trans):\n",
    "        self.splotre = np.transpose(splotre, (0, 2, 1))\n",
    "        self.lable = lable \n",
    "        self.transform = transform \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.splotre)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        splot = self.splotre[idx] \n",
    "        lable = self.lable[idx]\n",
    "        tensor = trans(splot)\n",
    "        return tensor, lable\n",
    "train_dataset = LocationDataset(train_splot, train_lable)\n",
    "loader_train = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataset = LocationDataset(val_splot, val_lable)\n",
    "loader_val = DataLoader(val_dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.4467,  7.3284,  7.3284,  7.0261,  7.0261,  6.5283,  6.2072,  6.2072,\n",
       "           5.7591,  5.4480],\n",
       "         [-0.1200, -0.2872, -0.2872, -0.5192, -0.5192, -0.6600, -0.6442, -0.6442,\n",
       "          -0.7500, -0.8589],\n",
       "         [ 1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,  1.5000,\n",
       "           1.5000,  1.5000]], device='cpu', dtype=torch.float64), 3.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_val.dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = False\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F  # useful stateless functions\n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model): \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 1.3999\n",
      "Got 247 / 1000 correct (24.70)\n",
      "\n",
      "Iteration 100, loss = 1.3963\n",
      "Got 232 / 1000 correct (23.20)\n",
      "\n",
      "Iteration 200, loss = 1.3397\n",
      "Got 213 / 1000 correct (21.30)\n",
      "\n",
      "Iteration 300, loss = 1.3932\n",
      "Got 211 / 1000 correct (21.10)\n",
      "\n",
      "Iteration 400, loss = 1.3447\n",
      "Got 333 / 1000 correct (33.30)\n",
      "\n",
      "Iteration 500, loss = 1.3521\n",
      "Got 332 / 1000 correct (33.20)\n",
      "\n",
      "Iteration 600, loss = 1.3100\n",
      "Got 420 / 1000 correct (42.00)\n",
      "\n",
      "Iteration 700, loss = 1.2614\n",
      "Got 541 / 1000 correct (54.10)\n",
      "\n",
      "Iteration 800, loss = 1.3064\n",
      "Got 422 / 1000 correct (42.20)\n",
      "\n",
      "Iteration 900, loss = 1.2914\n",
      "Got 680 / 1000 correct (68.00)\n",
      "\n",
      "Iteration 1000, loss = 1.1459\n",
      "Got 432 / 1000 correct (43.20)\n",
      "\n",
      "Iteration 1100, loss = 1.3097\n",
      "Got 720 / 1000 correct (72.00)\n",
      "\n",
      "Iteration 1200, loss = 1.2756\n",
      "Got 544 / 1000 correct (54.40)\n",
      "\n",
      "Iteration 1300, loss = 1.0951\n",
      "Got 429 / 1000 correct (42.90)\n",
      "\n",
      "Iteration 1400, loss = 1.1767\n",
      "Got 657 / 1000 correct (65.70)\n",
      "\n",
      "Iteration 1500, loss = 0.9755\n",
      "Got 680 / 1000 correct (68.00)\n",
      "\n",
      "Iteration 1600, loss = 1.1642\n",
      "Got 681 / 1000 correct (68.10)\n",
      "\n",
      "Iteration 1700, loss = 1.2192\n",
      "Got 706 / 1000 correct (70.60)\n",
      "\n",
      "Iteration 1800, loss = 0.9717\n",
      "Got 685 / 1000 correct (68.50)\n",
      "\n",
      "Iteration 1900, loss = 0.9478\n",
      "Got 717 / 1000 correct (71.70)\n",
      "\n",
      "Iteration 2000, loss = 0.8149\n",
      "Got 679 / 1000 correct (67.90)\n",
      "\n",
      "Iteration 2100, loss = 1.1885\n",
      "Got 633 / 1000 correct (63.30)\n",
      "\n",
      "Iteration 2200, loss = 1.1803\n",
      "Got 726 / 1000 correct (72.60)\n",
      "\n",
      "Iteration 2300, loss = 0.9867\n",
      "Got 684 / 1000 correct (68.40)\n",
      "\n",
      "Iteration 2400, loss = 0.8398\n",
      "Got 684 / 1000 correct (68.40)\n",
      "\n",
      "Iteration 2500, loss = 0.7747\n",
      "Got 709 / 1000 correct (70.90)\n",
      "\n",
      "Iteration 2600, loss = 1.1025\n",
      "Got 684 / 1000 correct (68.40)\n",
      "\n",
      "Iteration 2700, loss = 1.1487\n",
      "Got 682 / 1000 correct (68.20)\n",
      "\n",
      "Iteration 2800, loss = 0.7705\n",
      "Got 673 / 1000 correct (67.30)\n",
      "\n",
      "Iteration 2900, loss = 1.4337\n",
      "Got 717 / 1000 correct (71.70)\n",
      "\n",
      "Iteration 3000, loss = 0.6404\n",
      "Got 712 / 1000 correct (71.20)\n",
      "\n",
      "Iteration 3100, loss = 0.6224\n",
      "Got 779 / 1000 correct (77.90)\n",
      "\n",
      "Iteration 3200, loss = 0.9851\n",
      "Got 733 / 1000 correct (73.30)\n",
      "\n",
      "Iteration 3300, loss = 0.7593\n",
      "Got 723 / 1000 correct (72.30)\n",
      "\n",
      "Iteration 3400, loss = 0.6048\n",
      "Got 732 / 1000 correct (73.20)\n",
      "\n",
      "Iteration 3500, loss = 0.3883\n",
      "Got 739 / 1000 correct (73.90)\n",
      "\n",
      "Iteration 3600, loss = 0.8914\n",
      "Got 691 / 1000 correct (69.10)\n",
      "\n",
      "Iteration 3700, loss = 0.3972\n",
      "Got 766 / 1000 correct (76.60)\n",
      "\n",
      "Iteration 3800, loss = 0.4935\n",
      "Got 809 / 1000 correct (80.90)\n",
      "\n",
      "Iteration 3900, loss = 0.5708\n",
      "Got 792 / 1000 correct (79.20)\n",
      "\n",
      "Iteration 4000, loss = 0.7405\n",
      "Got 748 / 1000 correct (74.80)\n",
      "\n",
      "Iteration 4100, loss = 1.0092\n",
      "Got 730 / 1000 correct (73.00)\n",
      "\n",
      "Iteration 4200, loss = 0.8650\n",
      "Got 795 / 1000 correct (79.50)\n",
      "\n",
      "Iteration 4300, loss = 0.7732\n",
      "Got 807 / 1000 correct (80.70)\n",
      "\n",
      "Iteration 4400, loss = 0.5904\n",
      "Got 784 / 1000 correct (78.40)\n",
      "\n",
      "Iteration 4500, loss = 0.5685\n",
      "Got 786 / 1000 correct (78.60)\n",
      "\n",
      "Iteration 4600, loss = 0.2916\n",
      "Got 781 / 1000 correct (78.10)\n",
      "\n",
      "Iteration 4700, loss = 0.1543\n",
      "Got 835 / 1000 correct (83.50)\n",
      "\n",
      "Iteration 4800, loss = 0.1592\n",
      "Got 845 / 1000 correct (84.50)\n",
      "\n",
      "Iteration 4900, loss = 0.7963\n",
      "Got 833 / 1000 correct (83.30)\n",
      "\n",
      "Iteration 5000, loss = 0.1740\n",
      "Got 777 / 1000 correct (77.70)\n",
      "\n",
      "Iteration 5100, loss = 0.5311\n",
      "Got 803 / 1000 correct (80.30)\n",
      "\n",
      "Iteration 5200, loss = 0.5160\n",
      "Got 820 / 1000 correct (82.00)\n",
      "\n",
      "Iteration 5300, loss = 0.8222\n",
      "Got 832 / 1000 correct (83.20)\n",
      "\n",
      "Iteration 5400, loss = 0.6871\n",
      "Got 848 / 1000 correct (84.80)\n",
      "\n",
      "Iteration 5500, loss = 0.1582\n",
      "Got 859 / 1000 correct (85.90)\n",
      "\n",
      "Iteration 5600, loss = 0.4158\n",
      "Got 855 / 1000 correct (85.50)\n",
      "\n",
      "Iteration 5700, loss = 0.3891\n",
      "Got 798 / 1000 correct (79.80)\n",
      "\n",
      "Iteration 5800, loss = 0.2941\n",
      "Got 822 / 1000 correct (82.20)\n",
      "\n",
      "Iteration 5900, loss = 0.7243\n",
      "Got 810 / 1000 correct (81.00)\n",
      "\n",
      "Iteration 0, loss = 0.2490\n",
      "Got 853 / 1000 correct (85.30)\n",
      "\n",
      "Iteration 100, loss = 0.2029\n",
      "Got 843 / 1000 correct (84.30)\n",
      "\n",
      "Iteration 200, loss = 0.3952\n",
      "Got 836 / 1000 correct (83.60)\n",
      "\n",
      "Iteration 300, loss = 0.3386\n",
      "Got 852 / 1000 correct (85.20)\n",
      "\n",
      "Iteration 400, loss = 0.2687\n",
      "Got 852 / 1000 correct (85.20)\n",
      "\n",
      "Iteration 500, loss = 0.3283\n",
      "Got 855 / 1000 correct (85.50)\n",
      "\n",
      "Iteration 600, loss = 0.1442\n",
      "Got 866 / 1000 correct (86.60)\n",
      "\n",
      "Iteration 700, loss = 0.4456\n",
      "Got 858 / 1000 correct (85.80)\n",
      "\n",
      "Iteration 800, loss = 0.0382\n",
      "Got 856 / 1000 correct (85.60)\n",
      "\n",
      "Iteration 900, loss = 0.6721\n",
      "Got 836 / 1000 correct (83.60)\n",
      "\n",
      "Iteration 1000, loss = 0.5833\n",
      "Got 852 / 1000 correct (85.20)\n",
      "\n",
      "Iteration 1100, loss = 0.2589\n",
      "Got 829 / 1000 correct (82.90)\n",
      "\n",
      "Iteration 1200, loss = 1.0705\n",
      "Got 846 / 1000 correct (84.60)\n",
      "\n",
      "Iteration 1300, loss = 0.5119\n",
      "Got 870 / 1000 correct (87.00)\n",
      "\n",
      "Iteration 1400, loss = 0.1037\n",
      "Got 872 / 1000 correct (87.20)\n",
      "\n",
      "Iteration 1500, loss = 0.3751\n",
      "Got 869 / 1000 correct (86.90)\n",
      "\n",
      "Iteration 1600, loss = 0.0999\n",
      "Got 852 / 1000 correct (85.20)\n",
      "\n",
      "Iteration 1700, loss = 0.3681\n",
      "Got 874 / 1000 correct (87.40)\n",
      "\n",
      "Iteration 1800, loss = 0.0603\n",
      "Got 878 / 1000 correct (87.80)\n",
      "\n",
      "Iteration 1900, loss = 0.0910\n",
      "Got 865 / 1000 correct (86.50)\n",
      "\n",
      "Iteration 2000, loss = 0.3664\n",
      "Got 822 / 1000 correct (82.20)\n",
      "\n",
      "Iteration 2100, loss = 0.6447\n",
      "Got 864 / 1000 correct (86.40)\n",
      "\n",
      "Iteration 2200, loss = 0.8600\n",
      "Got 851 / 1000 correct (85.10)\n",
      "\n",
      "Iteration 2300, loss = 0.0211\n",
      "Got 868 / 1000 correct (86.80)\n",
      "\n",
      "Iteration 2400, loss = 0.3072\n",
      "Got 867 / 1000 correct (86.70)\n",
      "\n",
      "Iteration 2500, loss = 0.3558\n",
      "Got 875 / 1000 correct (87.50)\n",
      "\n",
      "Iteration 2600, loss = 0.1263\n",
      "Got 878 / 1000 correct (87.80)\n",
      "\n",
      "Iteration 2700, loss = 0.1074\n",
      "Got 868 / 1000 correct (86.80)\n",
      "\n",
      "Iteration 2800, loss = 0.4624\n",
      "Got 871 / 1000 correct (87.10)\n",
      "\n",
      "Iteration 2900, loss = 0.5902\n",
      "Got 880 / 1000 correct (88.00)\n",
      "\n",
      "Iteration 3000, loss = 0.4815\n",
      "Got 853 / 1000 correct (85.30)\n",
      "\n",
      "Iteration 3100, loss = 0.2295\n",
      "Got 849 / 1000 correct (84.90)\n",
      "\n",
      "Iteration 3200, loss = 0.0777\n",
      "Got 880 / 1000 correct (88.00)\n",
      "\n",
      "Iteration 3300, loss = 0.2378\n",
      "Got 867 / 1000 correct (86.70)\n",
      "\n",
      "Iteration 3400, loss = 0.1075\n",
      "Got 866 / 1000 correct (86.60)\n",
      "\n",
      "Iteration 3500, loss = 0.2881\n",
      "Got 880 / 1000 correct (88.00)\n",
      "\n",
      "Iteration 3600, loss = 0.1727\n",
      "Got 857 / 1000 correct (85.70)\n",
      "\n",
      "Iteration 3700, loss = 0.4867\n",
      "Got 870 / 1000 correct (87.00)\n",
      "\n",
      "Iteration 3800, loss = 0.5602\n",
      "Got 878 / 1000 correct (87.80)\n",
      "\n",
      "Iteration 3900, loss = 0.5228\n",
      "Got 843 / 1000 correct (84.30)\n",
      "\n",
      "Iteration 4000, loss = 0.1779\n",
      "Got 857 / 1000 correct (85.70)\n",
      "\n",
      "Iteration 4100, loss = 1.0492\n",
      "Got 862 / 1000 correct (86.20)\n",
      "\n",
      "Iteration 4200, loss = 0.8511\n",
      "Got 861 / 1000 correct (86.10)\n",
      "\n",
      "Iteration 4300, loss = 0.1020\n",
      "Got 837 / 1000 correct (83.70)\n",
      "\n",
      "Iteration 4400, loss = 0.3382\n",
      "Got 874 / 1000 correct (87.40)\n",
      "\n",
      "Iteration 4500, loss = 0.5123\n",
      "Got 830 / 1000 correct (83.00)\n",
      "\n",
      "Iteration 4600, loss = 0.0187\n",
      "Got 877 / 1000 correct (87.70)\n",
      "\n",
      "Iteration 4700, loss = 0.3105\n",
      "Got 886 / 1000 correct (88.60)\n",
      "\n",
      "Iteration 4800, loss = 0.3615\n",
      "Got 859 / 1000 correct (85.90)\n",
      "\n",
      "Iteration 4900, loss = 0.0578\n",
      "Got 876 / 1000 correct (87.60)\n",
      "\n",
      "Iteration 5000, loss = 0.2473\n",
      "Got 850 / 1000 correct (85.00)\n",
      "\n",
      "Iteration 5100, loss = 0.8446\n",
      "Got 854 / 1000 correct (85.40)\n",
      "\n",
      "Iteration 5200, loss = 0.1481\n",
      "Got 885 / 1000 correct (88.50)\n",
      "\n",
      "Iteration 5300, loss = 0.1769\n",
      "Got 886 / 1000 correct (88.60)\n",
      "\n",
      "Iteration 5400, loss = 0.2540\n",
      "Got 887 / 1000 correct (88.70)\n",
      "\n",
      "Iteration 5500, loss = 0.6087\n",
      "Got 815 / 1000 correct (81.50)\n",
      "\n",
      "Iteration 5600, loss = 0.3613\n",
      "Got 849 / 1000 correct (84.90)\n",
      "\n",
      "Iteration 5700, loss = 0.1892\n",
      "Got 878 / 1000 correct (87.80)\n",
      "\n",
      "Iteration 5800, loss = 0.1689\n",
      "Got 868 / 1000 correct (86.80)\n",
      "\n",
      "Iteration 5900, loss = 0.1766\n",
      "Got 867 / 1000 correct (86.70)\n",
      "\n",
      "Iteration 0, loss = 0.5582\n",
      "Got 885 / 1000 correct (88.50)\n",
      "\n",
      "Iteration 100, loss = 0.4919\n",
      "Got 833 / 1000 correct (83.30)\n",
      "\n",
      "Iteration 200, loss = 0.2718\n",
      "Got 881 / 1000 correct (88.10)\n",
      "\n",
      "Iteration 300, loss = 0.3394\n",
      "Got 865 / 1000 correct (86.50)\n",
      "\n",
      "Iteration 400, loss = 0.2313\n",
      "Got 880 / 1000 correct (88.00)\n",
      "\n",
      "Iteration 500, loss = 1.2527\n",
      "Got 882 / 1000 correct (88.20)\n",
      "\n",
      "Iteration 600, loss = 0.6020\n",
      "Got 884 / 1000 correct (88.40)\n",
      "\n",
      "Iteration 700, loss = 0.4533\n",
      "Got 877 / 1000 correct (87.70)\n",
      "\n",
      "Iteration 800, loss = 0.1681\n",
      "Got 877 / 1000 correct (87.70)\n",
      "\n",
      "Iteration 900, loss = 0.4859\n",
      "Got 888 / 1000 correct (88.80)\n",
      "\n",
      "Iteration 1000, loss = 0.3851\n",
      "Got 888 / 1000 correct (88.80)\n",
      "\n",
      "Iteration 1100, loss = 0.1261\n",
      "Got 892 / 1000 correct (89.20)\n",
      "\n",
      "Iteration 1200, loss = 0.5079\n",
      "Got 848 / 1000 correct (84.80)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1300, loss = 0.2121\n",
      "Got 884 / 1000 correct (88.40)\n",
      "\n",
      "Iteration 1400, loss = 0.7849\n",
      "Got 887 / 1000 correct (88.70)\n",
      "\n",
      "Iteration 1500, loss = 0.1491\n",
      "Got 866 / 1000 correct (86.60)\n",
      "\n",
      "Iteration 1600, loss = 0.0690\n",
      "Got 833 / 1000 correct (83.30)\n",
      "\n",
      "Iteration 1700, loss = 0.0434\n",
      "Got 866 / 1000 correct (86.60)\n",
      "\n",
      "Iteration 1800, loss = 0.1030\n",
      "Got 889 / 1000 correct (88.90)\n",
      "\n",
      "Iteration 1900, loss = 1.2946\n",
      "Got 879 / 1000 correct (87.90)\n",
      "\n",
      "Iteration 2000, loss = 0.3293\n",
      "Got 879 / 1000 correct (87.90)\n",
      "\n",
      "Iteration 2100, loss = 0.2074\n",
      "Got 856 / 1000 correct (85.60)\n",
      "\n",
      "Iteration 2200, loss = 0.5408\n",
      "Got 894 / 1000 correct (89.40)\n",
      "\n",
      "Iteration 2300, loss = 0.0106\n",
      "Got 849 / 1000 correct (84.90)\n",
      "\n",
      "Iteration 2400, loss = 0.1048\n",
      "Got 887 / 1000 correct (88.70)\n",
      "\n",
      "Iteration 2500, loss = 0.4537\n",
      "Got 823 / 1000 correct (82.30)\n",
      "\n",
      "Iteration 2600, loss = 0.1305\n",
      "Got 869 / 1000 correct (86.90)\n",
      "\n",
      "Iteration 2700, loss = 0.4225\n",
      "Got 862 / 1000 correct (86.20)\n",
      "\n",
      "Iteration 2800, loss = 0.3914\n",
      "Got 868 / 1000 correct (86.80)\n",
      "\n",
      "Iteration 2900, loss = 0.9579\n",
      "Got 860 / 1000 correct (86.00)\n",
      "\n",
      "Iteration 3000, loss = 0.0335\n",
      "Got 864 / 1000 correct (86.40)\n",
      "\n",
      "Iteration 3100, loss = 0.5743\n",
      "Got 891 / 1000 correct (89.10)\n",
      "\n",
      "Iteration 3200, loss = 0.0213\n",
      "Got 876 / 1000 correct (87.60)\n",
      "\n",
      "Iteration 3300, loss = 0.0493\n",
      "Got 879 / 1000 correct (87.90)\n",
      "\n",
      "Iteration 3400, loss = 0.1036\n",
      "Got 880 / 1000 correct (88.00)\n",
      "\n",
      "Iteration 3500, loss = 0.1371\n",
      "Got 862 / 1000 correct (86.20)\n",
      "\n",
      "Iteration 3600, loss = 0.0650\n",
      "Got 887 / 1000 correct (88.70)\n",
      "\n",
      "Iteration 3700, loss = 0.0537\n",
      "Got 872 / 1000 correct (87.20)\n",
      "\n",
      "Iteration 3800, loss = 0.2007\n",
      "Got 846 / 1000 correct (84.60)\n",
      "\n",
      "Iteration 3900, loss = 0.3498\n",
      "Got 886 / 1000 correct (88.60)\n",
      "\n",
      "Iteration 4000, loss = 0.0860\n",
      "Got 885 / 1000 correct (88.50)\n",
      "\n",
      "Iteration 4100, loss = 0.2004\n",
      "Got 880 / 1000 correct (88.00)\n",
      "\n",
      "Iteration 4200, loss = 0.0061\n",
      "Got 894 / 1000 correct (89.40)\n",
      "\n",
      "Iteration 4300, loss = 0.3739\n",
      "Got 853 / 1000 correct (85.30)\n",
      "\n",
      "Iteration 4400, loss = 0.1815\n",
      "Got 874 / 1000 correct (87.40)\n",
      "\n",
      "Iteration 4500, loss = 0.1986\n",
      "Got 897 / 1000 correct (89.70)\n",
      "\n",
      "Iteration 4600, loss = 0.0149\n",
      "Got 895 / 1000 correct (89.50)\n",
      "\n",
      "Iteration 4700, loss = 0.1470\n",
      "Got 842 / 1000 correct (84.20)\n",
      "\n",
      "Iteration 4800, loss = 0.0374\n",
      "Got 892 / 1000 correct (89.20)\n",
      "\n",
      "Iteration 4900, loss = 0.0266\n",
      "Got 874 / 1000 correct (87.40)\n",
      "\n",
      "Iteration 5000, loss = 0.0415\n",
      "Got 898 / 1000 correct (89.80)\n",
      "\n",
      "Iteration 5100, loss = 1.5340\n",
      "Got 880 / 1000 correct (88.00)\n",
      "\n",
      "Iteration 5200, loss = 0.8599\n",
      "Got 866 / 1000 correct (86.60)\n",
      "\n",
      "Iteration 5300, loss = 0.0934\n",
      "Got 904 / 1000 correct (90.40)\n",
      "\n",
      "Iteration 5400, loss = 0.0686\n",
      "Got 901 / 1000 correct (90.10)\n",
      "\n",
      "Iteration 5500, loss = 0.5220\n",
      "Got 875 / 1000 correct (87.50)\n",
      "\n",
      "Iteration 5600, loss = 1.7676\n",
      "Got 899 / 1000 correct (89.90)\n",
      "\n",
      "Iteration 5700, loss = 1.5572\n",
      "Got 897 / 1000 correct (89.70)\n",
      "\n",
      "Iteration 5800, loss = 0.3560\n",
      "Got 871 / 1000 correct (87.10)\n",
      "\n",
      "Iteration 5900, loss = 0.0297\n",
      "Got 897 / 1000 correct (89.70)\n",
      "\n",
      "Iteration 0, loss = 0.4754\n",
      "Got 863 / 1000 correct (86.30)\n",
      "\n",
      "Iteration 100, loss = 0.0553\n",
      "Got 883 / 1000 correct (88.30)\n",
      "\n",
      "Iteration 200, loss = 0.7026\n",
      "Got 902 / 1000 correct (90.20)\n",
      "\n",
      "Iteration 300, loss = 0.2135\n",
      "Got 889 / 1000 correct (88.90)\n",
      "\n",
      "Iteration 400, loss = 0.0272\n",
      "Got 871 / 1000 correct (87.10)\n",
      "\n",
      "Iteration 500, loss = 0.1440\n",
      "Got 891 / 1000 correct (89.10)\n",
      "\n",
      "Iteration 600, loss = 0.2458\n",
      "Got 903 / 1000 correct (90.30)\n",
      "\n",
      "Iteration 700, loss = 0.0739\n",
      "Got 635 / 1000 correct (63.50)\n",
      "\n",
      "Iteration 800, loss = 0.0693\n",
      "Got 894 / 1000 correct (89.40)\n",
      "\n",
      "Iteration 900, loss = 0.4768\n",
      "Got 888 / 1000 correct (88.80)\n",
      "\n",
      "Iteration 1000, loss = 0.1786\n",
      "Got 840 / 1000 correct (84.00)\n",
      "\n",
      "Iteration 1100, loss = 0.1622\n",
      "Got 893 / 1000 correct (89.30)\n",
      "\n",
      "Iteration 1200, loss = 0.0362\n",
      "Got 884 / 1000 correct (88.40)\n",
      "\n",
      "Iteration 1300, loss = 0.3079\n",
      "Got 900 / 1000 correct (90.00)\n",
      "\n",
      "Iteration 1400, loss = 0.2096\n",
      "Got 905 / 1000 correct (90.50)\n",
      "\n",
      "Iteration 1500, loss = 0.6311\n",
      "Got 896 / 1000 correct (89.60)\n",
      "\n",
      "Iteration 1600, loss = 0.3280\n",
      "Got 897 / 1000 correct (89.70)\n",
      "\n",
      "Iteration 1700, loss = 0.4298\n",
      "Got 880 / 1000 correct (88.00)\n",
      "\n",
      "Iteration 1800, loss = 0.3080\n",
      "Got 883 / 1000 correct (88.30)\n",
      "\n",
      "Iteration 1900, loss = 0.0408\n",
      "Got 885 / 1000 correct (88.50)\n",
      "\n",
      "Iteration 2000, loss = 0.0563\n",
      "Got 899 / 1000 correct (89.90)\n",
      "\n",
      "Iteration 2100, loss = 0.1921\n",
      "Got 865 / 1000 correct (86.50)\n",
      "\n",
      "Iteration 2200, loss = 0.0271\n",
      "Got 881 / 1000 correct (88.10)\n",
      "\n",
      "Iteration 2300, loss = 0.0857\n",
      "Got 898 / 1000 correct (89.80)\n",
      "\n",
      "Iteration 2400, loss = 0.0058\n",
      "Got 896 / 1000 correct (89.60)\n",
      "\n",
      "Iteration 2500, loss = 0.8373\n",
      "Got 896 / 1000 correct (89.60)\n",
      "\n",
      "Iteration 2600, loss = 0.1235\n",
      "Got 858 / 1000 correct (85.80)\n",
      "\n",
      "Iteration 2700, loss = 0.1714\n",
      "Got 886 / 1000 correct (88.60)\n",
      "\n",
      "Iteration 2800, loss = 0.2152\n",
      "Got 897 / 1000 correct (89.70)\n",
      "\n",
      "Iteration 2900, loss = 0.3367\n",
      "Got 900 / 1000 correct (90.00)\n",
      "\n",
      "Iteration 3000, loss = 0.0344\n",
      "Got 833 / 1000 correct (83.30)\n",
      "\n",
      "Iteration 3100, loss = 0.0020\n",
      "Got 846 / 1000 correct (84.60)\n",
      "\n",
      "Iteration 3200, loss = 0.0539\n",
      "Got 889 / 1000 correct (88.90)\n",
      "\n",
      "Iteration 3300, loss = 0.0826\n",
      "Got 873 / 1000 correct (87.30)\n",
      "\n",
      "Iteration 3400, loss = 0.5167\n",
      "Got 895 / 1000 correct (89.50)\n",
      "\n",
      "Iteration 3500, loss = 0.0479\n",
      "Got 911 / 1000 correct (91.10)\n",
      "\n",
      "Iteration 3600, loss = 0.0035\n",
      "Got 885 / 1000 correct (88.50)\n",
      "\n",
      "Iteration 3700, loss = 0.4494\n",
      "Got 884 / 1000 correct (88.40)\n",
      "\n",
      "Iteration 3800, loss = 0.2133\n",
      "Got 899 / 1000 correct (89.90)\n",
      "\n",
      "Iteration 3900, loss = 0.1012\n",
      "Got 880 / 1000 correct (88.00)\n",
      "\n",
      "Iteration 4000, loss = 0.1889\n",
      "Got 897 / 1000 correct (89.70)\n",
      "\n",
      "Iteration 4100, loss = 0.1987\n",
      "Got 907 / 1000 correct (90.70)\n",
      "\n",
      "Iteration 4200, loss = 0.3482\n",
      "Got 895 / 1000 correct (89.50)\n",
      "\n",
      "Iteration 4300, loss = 0.1509\n",
      "Got 874 / 1000 correct (87.40)\n",
      "\n",
      "Iteration 4400, loss = 0.3652\n",
      "Got 905 / 1000 correct (90.50)\n",
      "\n",
      "Iteration 4500, loss = 0.0152\n",
      "Got 899 / 1000 correct (89.90)\n",
      "\n",
      "Iteration 4600, loss = 0.1657\n",
      "Got 905 / 1000 correct (90.50)\n",
      "\n",
      "Iteration 4700, loss = 0.0257\n",
      "Got 906 / 1000 correct (90.60)\n",
      "\n",
      "Iteration 4800, loss = 0.1184\n",
      "Got 901 / 1000 correct (90.10)\n",
      "\n",
      "Iteration 4900, loss = 0.0028\n",
      "Got 907 / 1000 correct (90.70)\n",
      "\n",
      "Iteration 5000, loss = 0.1373\n",
      "Got 910 / 1000 correct (91.00)\n",
      "\n",
      "Iteration 5100, loss = 0.8629\n",
      "Got 911 / 1000 correct (91.10)\n",
      "\n",
      "Iteration 5200, loss = 0.6148\n",
      "Got 905 / 1000 correct (90.50)\n",
      "\n",
      "Iteration 5300, loss = 0.0837\n",
      "Got 879 / 1000 correct (87.90)\n",
      "\n",
      "Iteration 5400, loss = 0.3155\n",
      "Got 895 / 1000 correct (89.50)\n",
      "\n",
      "Iteration 5500, loss = 0.1378\n",
      "Got 910 / 1000 correct (91.00)\n",
      "\n",
      "Iteration 5600, loss = 0.0094\n",
      "Got 896 / 1000 correct (89.60)\n",
      "\n",
      "Iteration 5700, loss = 0.0687\n",
      "Got 908 / 1000 correct (90.80)\n",
      "\n",
      "Iteration 5800, loss = 0.0155\n",
      "Got 909 / 1000 correct (90.90)\n",
      "\n",
      "Iteration 5900, loss = 0.0710\n",
      "Got 915 / 1000 correct (91.50)\n",
      "\n",
      "Iteration 0, loss = 0.1400\n",
      "Got 897 / 1000 correct (89.70)\n",
      "\n",
      "Iteration 100, loss = 0.0542\n",
      "Got 898 / 1000 correct (89.80)\n",
      "\n",
      "Iteration 200, loss = 0.7227\n",
      "Got 883 / 1000 correct (88.30)\n",
      "\n",
      "Iteration 300, loss = 0.2912\n",
      "Got 900 / 1000 correct (90.00)\n",
      "\n",
      "Iteration 400, loss = 0.0898\n",
      "Got 909 / 1000 correct (90.90)\n",
      "\n",
      "Iteration 500, loss = 0.0001\n",
      "Got 900 / 1000 correct (90.00)\n",
      "\n",
      "Iteration 600, loss = 0.1134\n",
      "Got 887 / 1000 correct (88.70)\n",
      "\n",
      "Iteration 700, loss = 0.0303\n",
      "Got 915 / 1000 correct (91.50)\n",
      "\n",
      "Iteration 800, loss = 0.4153\n",
      "Got 911 / 1000 correct (91.10)\n",
      "\n",
      "Iteration 900, loss = 0.6802\n",
      "Got 916 / 1000 correct (91.60)\n",
      "\n",
      "Iteration 1000, loss = 0.1276\n",
      "Got 909 / 1000 correct (90.90)\n",
      "\n",
      "Iteration 1100, loss = 1.1107\n",
      "Got 907 / 1000 correct (90.70)\n",
      "\n",
      "Iteration 1200, loss = 0.1178\n",
      "Got 878 / 1000 correct (87.80)\n",
      "\n",
      "Iteration 1300, loss = 0.3040\n",
      "Got 874 / 1000 correct (87.40)\n",
      "\n",
      "Iteration 1400, loss = 0.0700\n",
      "Got 903 / 1000 correct (90.30)\n",
      "\n",
      "Iteration 1500, loss = 0.2951\n",
      "Got 909 / 1000 correct (90.90)\n",
      "\n",
      "Iteration 1600, loss = 0.0234\n",
      "Got 922 / 1000 correct (92.20)\n",
      "\n",
      "Iteration 1700, loss = 0.3914\n",
      "Got 916 / 1000 correct (91.60)\n",
      "\n",
      "Iteration 1800, loss = 1.0624\n",
      "Got 858 / 1000 correct (85.80)\n",
      "\n",
      "Iteration 1900, loss = 0.1235\n",
      "Got 911 / 1000 correct (91.10)\n",
      "\n",
      "Iteration 2000, loss = 0.0117\n",
      "Got 915 / 1000 correct (91.50)\n",
      "\n",
      "Iteration 2100, loss = 0.1192\n",
      "Got 900 / 1000 correct (90.00)\n",
      "\n",
      "Iteration 2200, loss = 0.0690\n",
      "Got 912 / 1000 correct (91.20)\n",
      "\n",
      "Iteration 2300, loss = 0.7715\n",
      "Got 913 / 1000 correct (91.30)\n",
      "\n",
      "Iteration 2400, loss = 0.2443\n",
      "Got 887 / 1000 correct (88.70)\n",
      "\n",
      "Iteration 2500, loss = 0.1982\n",
      "Got 920 / 1000 correct (92.00)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2600, loss = 0.8185\n",
      "Got 902 / 1000 correct (90.20)\n",
      "\n",
      "Iteration 2700, loss = 0.0427\n",
      "Got 861 / 1000 correct (86.10)\n",
      "\n",
      "Iteration 2800, loss = 0.2657\n",
      "Got 871 / 1000 correct (87.10)\n",
      "\n",
      "Iteration 2900, loss = 0.0172\n",
      "Got 883 / 1000 correct (88.30)\n",
      "\n",
      "Iteration 3000, loss = 0.0149\n",
      "Got 905 / 1000 correct (90.50)\n",
      "\n",
      "Iteration 3100, loss = 0.1333\n",
      "Got 924 / 1000 correct (92.40)\n",
      "\n",
      "Iteration 3200, loss = 0.2117\n",
      "Got 916 / 1000 correct (91.60)\n",
      "\n",
      "Iteration 3300, loss = 0.6886\n",
      "Got 897 / 1000 correct (89.70)\n",
      "\n",
      "Iteration 3400, loss = 0.1522\n",
      "Got 914 / 1000 correct (91.40)\n",
      "\n",
      "Iteration 3500, loss = 0.3314\n",
      "Got 902 / 1000 correct (90.20)\n",
      "\n",
      "Iteration 3600, loss = 0.1378\n",
      "Got 898 / 1000 correct (89.80)\n",
      "\n",
      "Iteration 3700, loss = 0.0635\n",
      "Got 916 / 1000 correct (91.60)\n",
      "\n",
      "Iteration 3800, loss = 0.1803\n",
      "Got 921 / 1000 correct (92.10)\n",
      "\n",
      "Iteration 3900, loss = 0.0349\n",
      "Got 904 / 1000 correct (90.40)\n",
      "\n",
      "Iteration 4000, loss = 0.1543\n",
      "Got 909 / 1000 correct (90.90)\n",
      "\n",
      "Iteration 4100, loss = 0.0950\n",
      "Got 897 / 1000 correct (89.70)\n",
      "\n",
      "Iteration 4200, loss = 0.0265\n",
      "Got 902 / 1000 correct (90.20)\n",
      "\n",
      "Iteration 4300, loss = 0.1200\n",
      "Got 879 / 1000 correct (87.90)\n",
      "\n",
      "Iteration 4400, loss = 0.6960\n",
      "Got 895 / 1000 correct (89.50)\n",
      "\n",
      "Iteration 4500, loss = 2.2648\n",
      "Got 924 / 1000 correct (92.40)\n",
      "\n",
      "Iteration 4600, loss = 0.2854\n",
      "Got 872 / 1000 correct (87.20)\n",
      "\n",
      "Iteration 4700, loss = 0.9971\n",
      "Got 910 / 1000 correct (91.00)\n",
      "\n",
      "Iteration 4800, loss = 0.4722\n",
      "Got 884 / 1000 correct (88.40)\n",
      "\n",
      "Iteration 4900, loss = 0.2242\n",
      "Got 923 / 1000 correct (92.30)\n",
      "\n",
      "Iteration 5000, loss = 0.0564\n",
      "Got 850 / 1000 correct (85.00)\n",
      "\n",
      "Iteration 5100, loss = 0.1610\n",
      "Got 904 / 1000 correct (90.40)\n",
      "\n",
      "Iteration 5200, loss = 0.1783\n",
      "Got 925 / 1000 correct (92.50)\n",
      "\n",
      "Iteration 5300, loss = 0.3858\n",
      "Got 893 / 1000 correct (89.30)\n",
      "\n",
      "Iteration 5400, loss = 0.3062\n",
      "Got 922 / 1000 correct (92.20)\n",
      "\n",
      "Iteration 5500, loss = 0.1788\n",
      "Got 917 / 1000 correct (91.70)\n",
      "\n",
      "Iteration 5600, loss = 0.5035\n",
      "Got 924 / 1000 correct (92.40)\n",
      "\n",
      "Iteration 5700, loss = 0.1620\n",
      "Got 895 / 1000 correct (89.50)\n",
      "\n",
      "Iteration 5800, loss = 0.6400\n",
      "Got 913 / 1000 correct (91.30)\n",
      "\n",
      "Iteration 5900, loss = 0.1233\n",
      "Got 913 / 1000 correct (91.30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_1 = 32 \n",
    "channel_2 = 16\n",
    "learning_rate = 1e-4\n",
    "model = None \n",
    "optimizer = None \n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv1d(3, 32, 3, stride = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(32, 64, 2, stride = 2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(64, 128, 3, stride = 2),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(512, 4)\n",
    ")\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9, nesterov = True)\n",
    "train_part34(model, optimizer,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LocationDataset(test_splot, test_lable)\n",
    "loader_test = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 3243 / 3633 correct (89.27)\n",
      "查准率0.8998174375914636\n",
      "召回率0.8968083215654922\n",
      "F1分数0.8951009080766331\n",
      "混淆矩阵\n",
      "[[681  11  41   0]\n",
      " [  6 743  33   0]\n",
      " [  1 189 807   0]\n",
      " [  0   0   0   0]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8998174375914636"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(loader,model):\n",
    "    num_correct = 0 \n",
    "    num_samples = 0 \n",
    "    res = []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device=device, dtype=dtype)\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "        scores = model(x)\n",
    "        _, preds = scores.max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "        res.append(preds.item())\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return res\n",
    "\n",
    "\n",
    "res = test(loader_test,model)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "def gradeOfClassifier():\n",
    "    P = metrics.precision_score(test_lable, res, average='macro')\n",
    "    R = metrics.recall_score(test_lable, res, average='macro')\n",
    "    # F1分数\n",
    "    F1 = metrics.f1_score(test_lable, res, average='weighted')\n",
    "    # 混淆矩阵\n",
    "    M = metrics.confusion_matrix(test_lable, res, labels=[1.0, 2.0, 3.0, 4.0])\n",
    "    print(\"查准率\" + str(P))\n",
    "    print(\"召回率\" + str(R))\n",
    "    print(\"F1分数\" + str(F1))\n",
    "    print(\"混淆矩阵\")\n",
    "    print(M)\n",
    "    print()\n",
    "    return P\n",
    "gradeOfClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 1.5182\n",
      "Got 240 / 1000 correct (24.00)\n",
      "\n",
      "Iteration 100, loss = 1.3058\n",
      "Got 298 / 1000 correct (29.80)\n",
      "\n",
      "Iteration 200, loss = 1.3460\n",
      "Got 379 / 1000 correct (37.90)\n",
      "\n",
      "Iteration 300, loss = 1.1209\n",
      "Got 476 / 1000 correct (47.60)\n",
      "\n",
      "Iteration 400, loss = 1.0910\n",
      "Got 597 / 1000 correct (59.70)\n",
      "\n",
      "Iteration 500, loss = 1.3460\n",
      "Got 497 / 1000 correct (49.70)\n",
      "\n",
      "Iteration 600, loss = 0.9905\n",
      "Got 499 / 1000 correct (49.90)\n",
      "\n",
      "Iteration 700, loss = 1.1513\n",
      "Got 560 / 1000 correct (56.00)\n",
      "\n",
      "Iteration 800, loss = 1.2812\n",
      "Got 489 / 1000 correct (48.90)\n",
      "\n",
      "Iteration 900, loss = 1.0333\n",
      "Got 427 / 1000 correct (42.70)\n",
      "\n",
      "Iteration 1000, loss = 0.9865\n",
      "Got 496 / 1000 correct (49.60)\n",
      "\n",
      "Iteration 1100, loss = 1.1688\n",
      "Got 632 / 1000 correct (63.20)\n",
      "\n",
      "Iteration 1200, loss = 1.0358\n",
      "Got 599 / 1000 correct (59.90)\n",
      "\n",
      "Iteration 1300, loss = 0.7743\n",
      "Got 620 / 1000 correct (62.00)\n",
      "\n",
      "Iteration 1400, loss = 1.1598\n",
      "Got 631 / 1000 correct (63.10)\n",
      "\n",
      "Iteration 1500, loss = 1.1555\n",
      "Got 613 / 1000 correct (61.30)\n",
      "\n",
      "Iteration 1600, loss = 1.1883\n",
      "Got 551 / 1000 correct (55.10)\n",
      "\n",
      "Iteration 1700, loss = 0.8908\n",
      "Got 631 / 1000 correct (63.10)\n",
      "\n",
      "Iteration 1800, loss = 1.2502\n",
      "Got 658 / 1000 correct (65.80)\n",
      "\n",
      "Iteration 1900, loss = 0.8029\n",
      "Got 691 / 1000 correct (69.10)\n",
      "\n",
      "Iteration 2000, loss = 0.9258\n",
      "Got 680 / 1000 correct (68.00)\n",
      "\n",
      "Iteration 2100, loss = 0.7982\n",
      "Got 610 / 1000 correct (61.00)\n",
      "\n",
      "Iteration 2200, loss = 1.0155\n",
      "Got 674 / 1000 correct (67.40)\n",
      "\n",
      "Iteration 2300, loss = 0.9131\n",
      "Got 695 / 1000 correct (69.50)\n",
      "\n",
      "Iteration 2400, loss = 1.0468\n",
      "Got 709 / 1000 correct (70.90)\n",
      "\n",
      "Iteration 2500, loss = 1.0495\n",
      "Got 692 / 1000 correct (69.20)\n",
      "\n",
      "Iteration 2600, loss = 0.6920\n",
      "Got 700 / 1000 correct (70.00)\n",
      "\n",
      "Iteration 2700, loss = 0.6660\n",
      "Got 742 / 1000 correct (74.20)\n",
      "\n",
      "Iteration 2800, loss = 0.7025\n",
      "Got 732 / 1000 correct (73.20)\n",
      "\n",
      "Iteration 2900, loss = 0.8573\n",
      "Got 734 / 1000 correct (73.40)\n",
      "\n",
      "Iteration 3000, loss = 0.5984\n",
      "Got 760 / 1000 correct (76.00)\n",
      "\n",
      "Iteration 3100, loss = 0.4880\n",
      "Got 751 / 1000 correct (75.10)\n",
      "\n",
      "Iteration 3200, loss = 0.4564\n",
      "Got 786 / 1000 correct (78.60)\n",
      "\n",
      "Iteration 3300, loss = 0.3432\n",
      "Got 736 / 1000 correct (73.60)\n",
      "\n",
      "Iteration 3400, loss = 0.6277\n",
      "Got 777 / 1000 correct (77.70)\n",
      "\n",
      "Iteration 3500, loss = 0.6711\n",
      "Got 824 / 1000 correct (82.40)\n",
      "\n",
      "Iteration 3600, loss = 0.7980\n",
      "Got 754 / 1000 correct (75.40)\n",
      "\n",
      "Iteration 3700, loss = 0.5123\n",
      "Got 784 / 1000 correct (78.40)\n",
      "\n",
      "Iteration 3800, loss = 0.3123\n",
      "Got 733 / 1000 correct (73.30)\n",
      "\n",
      "Iteration 3900, loss = 0.5229\n",
      "Got 787 / 1000 correct (78.70)\n",
      "\n",
      "Iteration 4000, loss = 0.3223\n",
      "Got 801 / 1000 correct (80.10)\n",
      "\n",
      "Iteration 4100, loss = 0.3774\n",
      "Got 822 / 1000 correct (82.20)\n",
      "\n",
      "Iteration 4200, loss = 0.6447\n",
      "Got 817 / 1000 correct (81.70)\n",
      "\n",
      "Iteration 4300, loss = 0.3141\n",
      "Got 812 / 1000 correct (81.20)\n",
      "\n",
      "Iteration 4400, loss = 0.1659\n",
      "Got 823 / 1000 correct (82.30)\n",
      "\n",
      "Iteration 4500, loss = 0.2729\n",
      "Got 785 / 1000 correct (78.50)\n",
      "\n",
      "Iteration 4600, loss = 0.4450\n",
      "Got 844 / 1000 correct (84.40)\n",
      "\n",
      "Iteration 4700, loss = 0.1482\n",
      "Got 808 / 1000 correct (80.80)\n",
      "\n",
      "Iteration 4800, loss = 0.7670\n",
      "Got 816 / 1000 correct (81.60)\n",
      "\n",
      "Iteration 4900, loss = 0.5191\n",
      "Got 816 / 1000 correct (81.60)\n",
      "\n",
      "Iteration 5000, loss = 0.2834\n",
      "Got 816 / 1000 correct (81.60)\n",
      "\n",
      "Iteration 5100, loss = 0.4412\n",
      "Got 801 / 1000 correct (80.10)\n",
      "\n",
      "Iteration 5200, loss = 0.8237\n",
      "Got 796 / 1000 correct (79.60)\n",
      "\n",
      "Iteration 5300, loss = 1.3245\n",
      "Got 864 / 1000 correct (86.40)\n",
      "\n",
      "Iteration 5400, loss = 0.3406\n",
      "Got 846 / 1000 correct (84.60)\n",
      "\n",
      "Iteration 5500, loss = 0.7034\n",
      "Got 855 / 1000 correct (85.50)\n",
      "\n",
      "Iteration 5600, loss = 0.3646\n",
      "Got 864 / 1000 correct (86.40)\n",
      "\n",
      "Iteration 5700, loss = 0.4666\n",
      "Got 816 / 1000 correct (81.60)\n",
      "\n",
      "Iteration 5800, loss = 0.1566\n",
      "Got 859 / 1000 correct (85.90)\n",
      "\n",
      "Iteration 5900, loss = 0.6770\n",
      "Got 856 / 1000 correct (85.60)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_1 = 32 \n",
    "channel_2 = 16\n",
    "learning_rate = 1e-4\n",
    "model = None \n",
    "optimizer = None \n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv1d(3, 32, 3, stride = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(32, 64, 2, stride = 2),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(576, 4)\n",
    ")\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9, nesterov = True)\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradeOfClassifer():\n",
    "    np.set_printoptions(suppress=True)\n",
    "    x, lable = extrat.normData(slot)\n",
    "\n",
    "    x_train, x_test, lable_train, lable_test = train_test_split(x, lable, random_state=1, train_size=0.4,\n",
    "                                                                test_size=0.6)  # 将数据集按比例划分为训练集和测试集\n",
    "    # if kenel == 0:\n",
    "    #     clf = svm.SVC(C=0.8, kernel=\"rbf\", gamma=20, decision_function_shape='ovr')\n",
    "    # elif kenel == 1:\n",
    "    #   clf = svm.SVC(C=0.8, kernel=\"linear\", gamma=20, decision_function_shape='ovr')\n",
    "    # elif kenel == 2:\n",
    "    #     clf = svm.SVC(C=0.8, kernel=\"poly\", gamma=20, degree=3, decision_function_shape='ovr')\n",
    "    # else:\n",
    "    #     clf = svm.SVC(C=0.8, kernel=\"sigmoid\", gamma=20, decision_function_shape='ovr')\n",
    "    # clf = svm.SVC(C=0.8, kernel=\"poly\", gamma=20, degree=3, decision_function_shape='ovr')\n",
    "    clf = svm.SVC(C=0.8, kernel=\"linear\", gamma=20, decision_function_shape='ovr')\n",
    "    clf.fit(x_train, lable_train.ravel())  # 提供训练集和标签 训练svm\n",
    "    pre = clf.predict(x_test)  # 预测\n",
    "\n",
    "    # 查准率（正确率）\n",
    "    P = metrics.precision_score(lable_test, pre, average='macro')\n",
    "    # 召回率\n",
    "    R = metrics.recall_score(lable_test, pre, average='macro')\n",
    "    # F1分数\n",
    "    F1 = metrics.f1_score(lable_test, pre, average='weighted')\n",
    "    # 混淆矩阵\n",
    "    M = metrics.confusion_matrix(lable_test, pre, labels=[1.0, 2.0, 3.0, 4.0])\n",
    "    print(\"查准率\" + str(P))\n",
    "    print(\"召回率\" + str(R))\n",
    "    print(\"F1分数\" + str(F1))\n",
    "    print(\"混淆矩阵\")\n",
    "    print(M)\n",
    "    print()\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, e in enumerate(loader_train):\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
