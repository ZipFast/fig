{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime \n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "##文件数据行为: x   y   z  time     ；表示一个坐标点的三个坐标分量和 采集时间 ，使用空格符分隔\n",
    "\n",
    "def pre(source, distance, diantance1):\n",
    "    f = open(source, \"r\")  # 源文件\n",
    "    fwrit = open(distance, \"a\")  # 卡2068\n",
    "    for s in f.readlines():\n",
    "        if len(s) == 1:\n",
    "            fwrit.write(s)\n",
    "        else:\n",
    "            s = s[:-1]\n",
    "            tem = s.split()\n",
    "            re = tem[1].split(':')[1] + \"\\t\" + tem[2].split(':')[1] + \"\\t\" + tem[3].split(':')[1] + \"\\t\" + tem[-2] + \"\\t\" + tem[-1] + \"\\n\"\n",
    "            # if tem[0] != \"2068\":\n",
    "            #     fwrit1.write(re)\n",
    "            # else:\n",
    "            if tem[0] == \"2068\":\n",
    "                fwrit.write(re)\n",
    "    f.close()\n",
    "    fwrit.close()\n",
    "\n",
    "\n",
    "def file_name(file_dir, target, target1):\n",
    "    path = [file_dir + '\\\\' + x for x in os.listdir(file_dir)]\n",
    "    for p in path:\n",
    "        if not os.path.isdir(p):\n",
    "            pre(p, target, target1)\n",
    "\n",
    "def split_data(splot):\n",
    "    \"\"\"\n",
    "    按照plot划分时间段\n",
    "    \"\"\"\n",
    "    state = \"D:\\\\fig\\\\data\\\\pre2068Static.txt\"\n",
    "    unrealize = \"D:\\\\fig\\\\data\\\\pre2068Unrealize.txt\"\n",
    "    Sactive = \"D:\\\\fig\\\\data\\\\pre2068Little.txt\"\n",
    "    Mactive = \"D:\\\\fig\\\\data\\\\pre2068LargeMove.txt\"\n",
    "    files = [state, unrealize, Sactive, Mactive]\n",
    "    mask = [1., 2., 3., 4.]\n",
    "    splotre = []\n",
    "    lable = [] \n",
    "    for index, file in enumerate(files):\n",
    "        f = open(file, \"r\")\n",
    "        mk = mask[index]\n",
    "\n",
    "        flag = False \n",
    "        start = ''\n",
    "        obj = [] \n",
    "        for s in f.readlines():\n",
    "            if len(s) <= 1:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                s = s[:-1]\n",
    "                seq = s.split(\"\\t\")\n",
    "                if flag == False :\n",
    "                    #本数据序列第一点的采集时间\n",
    "                    start = 0\n",
    "                    now = 0\n",
    "                    flag = True \n",
    "                # 当前点的采集时间\n",
    "                now = now + 1\n",
    "                subt = now - start \n",
    "                obj.append(np.asarray(seq[:3],dtype='float64'))\n",
    "                obj.append(index+1)\n",
    "            if subt > splot:\n",
    "                splotre.append(np.asarray(obj))\n",
    "                lable.append(index+1)\n",
    "                obj.clear() \n",
    "                flag = False\n",
    "    splotre = np.asarray(splotre)\n",
    "    lable = np.asarray(lable)\n",
    "    return splotre, lable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大幅度运动 原始数据源\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\active\"\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068LargeMove.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preLargeMove.txt\"  # 其他卡的处理结果\n",
    "\n",
    "file_name(p, t, t1)\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\little\"  # 原始数据源\n",
    "\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Little.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preLittle.txt\"  # 其他卡的处理结果\n",
    "\n",
    "file_name(p, t, t1)\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\static\"  # 原始数据源\n",
    "\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Static.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preStatic.txt\"  # 其他卡的处理结果\n",
    "file_name(p, t, t1)\n",
    "# 无意识运动，如转身，手摆动\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\unrealize\"  # 原始数据源\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Unrealize.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preUnrealize.txt\"  # 其他卡的处理结果径\n",
    "file_name(p, t, t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([4.80734, 0.89978, 1.5    ]), 1,\n",
       "        array([4.80734, 0.89978, 1.5    ]), ..., 1,\n",
       "        array([4.80734, 0.89978, 1.5    ]), 1],\n",
       "       [array([4.80734, 0.89978, 1.5    ]), 1,\n",
       "        array([4.80734, 0.89978, 1.5    ]), ..., 1,\n",
       "        array([4.80734, 0.89978, 1.5    ]), 1],\n",
       "       [array([4.80734, 0.89978, 1.5    ]), 1,\n",
       "        array([4.80734, 0.89978, 1.5    ]), ..., 1,\n",
       "        array([4.80734, 0.89978, 1.5    ]), 1],\n",
       "       ...,\n",
       "       [array([ 6.69377, -0.45626,  1.5    ]), 4,\n",
       "        array([ 6.69377, -0.45626,  1.5    ]), ..., 4,\n",
       "        array([7.70676, 2.93816, 1.5    ]), 4],\n",
       "       [array([7.37501, 3.22528, 1.5    ]), 4,\n",
       "        array([7.1112 , 3.16778, 1.5    ]), ..., 4,\n",
       "        array([8.09285, 1.8695 , 1.5    ]), 4],\n",
       "       [array([8.06092, 1.57082, 1.5    ]), 4,\n",
       "        array([8.06064, 1.31173, 1.5    ]), ..., 4,\n",
       "        array([ 4.95262, -0.64923,  1.5    ]), 4]], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splotre, lable = split_data(19)\n",
    "splotre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 25000\n",
    "loader_train = DataLoader(splotre[:NUM_TRAIN+1000], batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "loader_val = DataLoader(splotre[:NUM_TRAIN+1000], batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, NUM_TRAIN+1000)))\n",
    "loader_test = loader_test = DataLoader(splotre[NUM_TRAIN+1000:], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F  # useful stateless functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_1 = 32 \n",
    "channel_2 = 16\n",
    "learning_rate = 1e-4\n",
    "model = None \n",
    "optimizer = None \n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv1d(20, 100, 1, stride = 1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(channel_2*20, 4)\n",
    ")\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9, nesterov = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([4.80734, 0.89978, 1.5    ]), 1,\n",
       "        array([4.80734, 0.89978, 1.5    ]), ..., 1,\n",
       "        array([4.80734, 0.89978, 1.5    ]), 1],\n",
       "       [array([4.80734, 0.89978, 1.5    ]), 1,\n",
       "        array([4.80734, 0.89978, 1.5    ]), ..., 1,\n",
       "        array([4.80734, 0.89978, 1.5    ]), 1],\n",
       "       [array([4.80734, 0.89978, 1.5    ]), 1,\n",
       "        array([4.80734, 0.89978, 1.5    ]), ..., 1,\n",
       "        array([4.80734, 0.89978, 1.5    ]), 1],\n",
       "       ...,\n",
       "       [array([ 7.52228, -1.17309,  1.5    ]), 4,\n",
       "        array([ 7.52228, -1.17309,  1.5    ]), ..., 4,\n",
       "        array([7.90362, 2.29734, 1.5    ]), 4],\n",
       "       [array([7.60549, 2.93141, 1.5    ]), 4,\n",
       "        array([7.60549, 2.93141, 1.5    ]), ..., 4,\n",
       "        array([6.46161, 2.58947, 1.5    ]), 4],\n",
       "       [array([6.68871, 2.653  , 1.5    ]), 4,\n",
       "        array([6.90401, 2.70289, 1.5    ]), ..., 4,\n",
       "        array([ 7.79849, -0.29005,  1.5    ]), 4]], dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-16ad818ca342>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_part34\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-116-0807bf043cab>\u001b[0m in \u001b[0;36mtrain_part34\u001b[1;34m(model, optimizer, epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# move the model parameters to CPU/GPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# put model to training mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# move to device, e.g. GPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;31m# array of string classes and object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp_str_obj_array_pattern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object"
     ]
    }
   ],
   "source": [
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
