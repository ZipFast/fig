{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime \n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "##文件数据行为: x   y   z  time     ；表示一个坐标点的三个坐标分量和 采集时间 ，使用空格符分隔\n",
    "\n",
    "def pre(source, distance, diantance1):\n",
    "    f = open(source, \"r\")  # 源文件\n",
    "    fwrit = open(distance, \"a\")  # 卡2068\n",
    "    for s in f.readlines():\n",
    "        if len(s) == 1:\n",
    "            fwrit.write(s)\n",
    "        else:\n",
    "            s = s[:-1]\n",
    "            tem = s.split()\n",
    "            re = tem[1].split(':')[1] + \"\\t\" + tem[2].split(':')[1] + \"\\t\" + tem[3].split(':')[1] + \"\\t\" + tem[-2] + \"\\t\" + tem[-1] + \"\\n\"\n",
    "            # if tem[0] != \"2068\":\n",
    "            #     fwrit1.write(re)\n",
    "            # else:\n",
    "            if tem[0] == \"2068\":\n",
    "                fwrit.write(re)\n",
    "    f.close()\n",
    "    fwrit.close()\n",
    "\n",
    "\n",
    "def file_name(file_dir, target, target1):\n",
    "    path = [file_dir + '\\\\' + x for x in os.listdir(file_dir)]\n",
    "    for p in path:\n",
    "        if not os.path.isdir(p):\n",
    "            pre(p, target, target1)\n",
    "\n",
    "def split_data(splot):\n",
    "    \"\"\"\n",
    "    按照plot划分时间段\n",
    "    \"\"\"\n",
    "    state = \"D:\\\\fig\\\\data\\\\pre2068Static.txt\"\n",
    "    unrealize = \"D:\\\\fig\\\\data\\\\pre2068Unrealize.txt\"\n",
    "    Sactive = \"D:\\\\fig\\\\data\\\\pre2068Little.txt\"\n",
    "    Mactive = \"D:\\\\fig\\\\data\\\\pre2068LargeMove.txt\"\n",
    "    files = [state, unrealize, Sactive, Mactive]\n",
    "    mask = [1., 2., 3., 4.]\n",
    "    splotre = []\n",
    "    lable = [] \n",
    "    for index, file in enumerate(files):\n",
    "        f = open(file, \"r\")\n",
    "        mk = mask[index]\n",
    "\n",
    "        flag = False \n",
    "        start = ''\n",
    "        obj = [] \n",
    "        for s in f.readlines():\n",
    "            if len(s) <= 1:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                s = s[:-1]\n",
    "                seq = s.split(\"\\t\")\n",
    "                if flag == False :\n",
    "                    #本数据序列第一点的采集时间\n",
    "                    start = 0\n",
    "                    now = 0\n",
    "                    flag = True \n",
    "                # 当前点的采集时间\n",
    "                now = now + 1\n",
    "                subt = now - start \n",
    "                obj.append(np.asarray(seq[:3],dtype='float64'))\n",
    "            if subt > splot:\n",
    "                splotre.append(np.asarray(obj))\n",
    "                lable.append(mk)\n",
    "                obj.clear() \n",
    "                flag = False\n",
    "    splotre = np.asarray(splotre)\n",
    "    lable = np.asarray(lable)\n",
    "    return splotre, lable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大幅度运动 原始数据源\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\active\"\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068LargeMove.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preLargeMove.txt\"  # 其他卡的处理结果\n",
    "\n",
    "file_name(p, t, t1)\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\little\"  # 原始数据源\n",
    "\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Little.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preLittle.txt\"  # 其他卡的处理结果\n",
    "\n",
    "file_name(p, t, t1)\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\static\"  # 原始数据源\n",
    "\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Static.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preStatic.txt\"  # 其他卡的处理结果\n",
    "file_name(p, t, t1)\n",
    "# 无意识运动，如转身，手摆动\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\unrealize\"  # 原始数据源\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Unrealize.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preUnrealize.txt\"  # 其他卡的处理结果径\n",
    "file_name(p, t, t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        ...,\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ]],\n",
       "\n",
       "       [[ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        ...,\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ]],\n",
       "\n",
       "       [[ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        ...,\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 6.69377, -0.45626,  1.5    ],\n",
       "        [ 6.69377, -0.45626,  1.5    ],\n",
       "        [ 7.21234, -0.38367,  1.5    ],\n",
       "        ...,\n",
       "        [ 7.88736,  2.65041,  1.5    ],\n",
       "        [ 7.70676,  2.93816,  1.5    ],\n",
       "        [ 7.70676,  2.93816,  1.5    ]],\n",
       "\n",
       "       [[ 7.37501,  3.22528,  1.5    ],\n",
       "        [ 7.1112 ,  3.16778,  1.5    ],\n",
       "        [ 6.86056,  3.14418,  1.5    ],\n",
       "        ...,\n",
       "        [ 8.18929,  2.28952,  1.5    ],\n",
       "        [ 8.18482,  2.08379,  1.5    ],\n",
       "        [ 8.09285,  1.8695 ,  1.5    ]],\n",
       "\n",
       "       [[ 8.06092,  1.57082,  1.5    ],\n",
       "        [ 8.06064,  1.31173,  1.5    ],\n",
       "        [ 8.03174,  1.06668,  1.5    ],\n",
       "        ...,\n",
       "        [ 5.47525, -0.73263,  1.5    ],\n",
       "        [ 5.1933 , -0.66509,  1.5    ],\n",
       "        [ 4.95262, -0.64923,  1.5    ]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splotre, lable = split_data(19)\n",
    "splotre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division \n",
    "import os \n",
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision import transforms, utils\n",
    "class LocationDataset(Dataset):\n",
    "    def __init__(self, splotre, lable, transform = None):\n",
    "        self.splotre = splotre \n",
    "        self.lable = lable \n",
    "        self.transform = transform \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.splotre)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        splot = self.splotre[idx] \n",
    "        lable = self.lable[idx]\n",
    "        \n",
    "        sample = {'dataset':splot, 'lable':lable}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LocationDataset(splotre, lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-ad8c40f830c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lable'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "sample = dataset[1]\n",
    "sample['lable'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 4., 4., 4.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class   ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        dataset, lable = sample['dataset'], sample['lable'] \n",
    "        dataset = dataset.transpose((1, 0)) \n",
    "        return {\n",
    "            'dataset': torch.from_numpy(dataset),\n",
    "            'lable': lable\n",
    "        }\n",
    "dataset = LocationDataset(splotre, lable, transform=transforms.Compose([ToTensor()]))\n",
    "index = np.random.shuffle(range(len()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 25000\n",
    "loader_train = DataLoader(splotre[:NUM_TRAIN+1000], batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "loader_val = DataLoader(splotre[:NUM_TRAIN+1000], batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, NUM_TRAIN+1000)))\n",
    "loader_test = loader_test = DataLoader(splotre[NUM_TRAIN+1000:], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F  # useful stateless functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_1 = 32 \n",
    "channel_2 = 16\n",
    "learning_rate = 1e-4\n",
    "model = None \n",
    "optimizer = None \n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv1d(20, 100, 1, stride = 1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(channel_2*20, 4)\n",
    ")\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9, nesterov = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "file = pd.read_csv('D:\\\\fig\\\\data\\\\pre2068LargeMove.txt', sep = '\\t')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
