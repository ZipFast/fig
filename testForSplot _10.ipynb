{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision import transforms, utils\n",
    "import os\n",
    "import datetime \n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "##文件数据行为: x   y   z  time     ；表示一个坐标点的三个坐标分量和 采集时间 ，使用空格符分隔\n",
    "\n",
    "def pre(source, distance, diantance1):\n",
    "    f = open(source, \"r\")  # 源文件\n",
    "    fwrit = open(distance, \"a\")  # 卡2068\n",
    "    for s in f.readlines():\n",
    "        if len(s) == 1:\n",
    "            fwrit.write(s)\n",
    "        else:\n",
    "            s = s[:-1]\n",
    "            tem = s.split()\n",
    "            re = tem[1].split(':')[1] + \"\\t\" + tem[2].split(':')[1] + \"\\t\" + tem[3].split(':')[1] + \"\\t\" + tem[-2] + \"\\t\" + tem[-1] + \"\\n\"\n",
    "            # if tem[0] != \"2068\":\n",
    "            #     fwrit1.write(re)\n",
    "            # else:\n",
    "            if tem[0] == \"2068\":\n",
    "                fwrit.write(re)\n",
    "    f.close()\n",
    "    fwrit.close()\n",
    "\n",
    "\n",
    "def file_name(file_dir, target, target1):\n",
    "    path = [file_dir + '\\\\' + x for x in os.listdir(file_dir)]\n",
    "    for p in path:\n",
    "        if not os.path.isdir(p):\n",
    "            pre(p, target, target1)\n",
    "\n",
    "def split_data(splot):\n",
    "    \"\"\"\n",
    "    按照plot划分时间段\n",
    "    \"\"\"\n",
    "    state = \"D:\\\\fig\\\\data\\\\pre2068Static.txt\"\n",
    "    unrealize = \"D:\\\\fig\\\\data\\\\pre2068Unrealize.txt\"\n",
    "    Sactive = \"D:\\\\fig\\\\data\\\\pre2068Little.txt\"\n",
    "    Mactive = \"D:\\\\fig\\\\data\\\\pre2068LargeMove.txt\"\n",
    "    files = [state, unrealize, Sactive, Mactive]\n",
    "    mask = [0., 1., 2., 3.]\n",
    "    splotre = []\n",
    "    lable = [] \n",
    "    for index, file in enumerate(files):\n",
    "        f = open(file, \"r\")\n",
    "        mk = mask[index]\n",
    "\n",
    "        flag = False \n",
    "        start = ''\n",
    "        obj = [] \n",
    "        for s in f.readlines():\n",
    "            if len(s) <= 1:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                s = s[:-1]\n",
    "                seq = s.split(\"\\t\")\n",
    "                if flag == False :\n",
    "                    #本数据序列第一点的采集时间\n",
    "                    start = 0\n",
    "                    now = 0\n",
    "                    flag = True \n",
    "                # 当前点的采集时间\n",
    "                now = now + 1\n",
    "                subt = now - start \n",
    "                obj.append(np.asarray(seq[:3],dtype='float64'))\n",
    "            if subt > splot:\n",
    "                splotre.append(np.asarray(obj))\n",
    "                lable.append(mk)\n",
    "                obj.clear() \n",
    "                flag = False\n",
    "    splotre = np.asarray(splotre)\n",
    "    lable = np.asarray(lable)\n",
    "    return splotre, lable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大幅度运动 原始数据源\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\active\"\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068LargeMove.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preLargeMove.txt\"  # 其他卡的处理结果\n",
    "\n",
    "file_name(p, t, t1)\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\little\"  # 原始数据源\n",
    "\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Little.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preLittle.txt\"  # 其他卡的处理结果\n",
    "\n",
    "file_name(p, t, t1)\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\static\"  # 原始数据源\n",
    "\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Static.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preStatic.txt\"  # 其他卡的处理结果\n",
    "file_name(p, t, t1)\n",
    "# 无意识运动，如转身，手摆动\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\unrealize\"  # 原始数据源\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Unrealize.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preUnrealize.txt\"  # 其他卡的处理结果径\n",
    "file_name(p, t, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "splotre, lable = split_data(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28633, 20, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splotre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 3., 3., 3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 20000\n",
    "index = list(range(splotre.shape[0]))\n",
    "np.random.shuffle(index)\n",
    "splotre = splotre[index]\n",
    "lable = lable[index]\n",
    "train_splot = splotre[:NUM_TRAIN-3000]\n",
    "train_lable = lable[:NUM_TRAIN-3000]\n",
    "val_splot = splotre[NUM_TRAIN-3000:NUM_TRAIN]\n",
    "val_lable = lable[NUM_TRAIN-3000:NUM_TRAIN]\n",
    "test_splot = splotre[NUM_TRAIN:]\n",
    "test_lable = lable[NUM_TRAIN:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, splot):\n",
    "        return torch.from_numpy(splot)\n",
    "    \n",
    "trans = T.Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "class LocationDataset(Dataset):\n",
    "    def __init__(self, splotre, lable, transform = trans):\n",
    "        self.splotre = np.transpose(splotre, (0, 2, 1))\n",
    "        self.lable = lable \n",
    "        self.transform = transform \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.splotre)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        splot = self.splotre[idx] \n",
    "        lable = self.lable[idx]\n",
    "        tensor = trans(splot)\n",
    "        return tensor, lable\n",
    "train_dataset = LocationDataset(train_splot, train_lable)\n",
    "loader_train = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataset = LocationDataset(val_splot, val_lable)\n",
    "loader_val = DataLoader(val_dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[7.1165, 7.1305, 7.1314, 7.1004, 7.0689, 7.0582, 7.0583, 7.0650, 7.0071,\n",
       "          6.9706, 6.9716, 6.9406, 6.9406, 6.9406, 6.9406, 6.9406, 6.9406, 6.9406,\n",
       "          6.9406, 6.9406],\n",
       "         [1.9992, 2.0352, 2.0903, 2.1640, 2.2232, 2.2454, 2.2395, 2.2357, 2.2364,\n",
       "          2.2033, 2.1919, 2.1892, 2.1892, 2.1892, 2.1892, 2.1892, 2.1892, 2.1892,\n",
       "          2.1892, 2.1892],\n",
       "         [1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "          1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "          1.5000, 1.5000]], device='cpu', dtype=torch.float64), 1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_val.dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = False\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F  # useful stateless functions\n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model): \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 1.3664\n",
      "Got 916 / 3000 correct (30.53)\n",
      "\n",
      "Iteration 100, loss = 1.3333\n",
      "Got 1042 / 3000 correct (34.73)\n",
      "\n",
      "Iteration 200, loss = 1.3661\n",
      "Got 922 / 3000 correct (30.73)\n",
      "\n",
      "Iteration 300, loss = 1.3667\n",
      "Got 1079 / 3000 correct (35.97)\n",
      "\n",
      "Iteration 400, loss = 1.2993\n",
      "Got 1602 / 3000 correct (53.40)\n",
      "\n",
      "Iteration 500, loss = 1.1344\n",
      "Got 1216 / 3000 correct (40.53)\n",
      "\n",
      "Iteration 600, loss = 1.2800\n",
      "Got 1546 / 3000 correct (51.53)\n",
      "\n",
      "Iteration 700, loss = 1.2634\n",
      "Got 1805 / 3000 correct (60.17)\n",
      "\n",
      "Iteration 800, loss = 1.3404\n",
      "Got 1692 / 3000 correct (56.40)\n",
      "\n",
      "Iteration 900, loss = 1.2258\n",
      "Got 1691 / 3000 correct (56.37)\n",
      "\n",
      "Iteration 1000, loss = 1.0768\n",
      "Got 1820 / 3000 correct (60.67)\n",
      "\n",
      "Iteration 1100, loss = 1.2567\n",
      "Got 1799 / 3000 correct (59.97)\n",
      "\n",
      "Iteration 1200, loss = 1.0464\n",
      "Got 1899 / 3000 correct (63.30)\n",
      "\n",
      "Iteration 1300, loss = 1.0813\n",
      "Got 1967 / 3000 correct (65.57)\n",
      "\n",
      "Iteration 1400, loss = 1.0976\n",
      "Got 1995 / 3000 correct (66.50)\n",
      "\n",
      "Iteration 1500, loss = 1.0254\n",
      "Got 2070 / 3000 correct (69.00)\n",
      "\n",
      "Iteration 1600, loss = 0.8542\n",
      "Got 1929 / 3000 correct (64.30)\n",
      "\n",
      "Iteration 1700, loss = 0.9409\n",
      "Got 1730 / 3000 correct (57.67)\n",
      "\n",
      "Iteration 1800, loss = 1.2587\n",
      "Got 2055 / 3000 correct (68.50)\n",
      "\n",
      "Iteration 1900, loss = 0.7606\n",
      "Got 2089 / 3000 correct (69.63)\n",
      "\n",
      "Iteration 2000, loss = 0.7997\n",
      "Got 2050 / 3000 correct (68.33)\n",
      "\n",
      "Iteration 2100, loss = 0.6104\n",
      "Got 2164 / 3000 correct (72.13)\n",
      "\n",
      "Iteration 2200, loss = 1.0604\n",
      "Got 2104 / 3000 correct (70.13)\n",
      "\n",
      "Iteration 2300, loss = 0.6727\n",
      "Got 2211 / 3000 correct (73.70)\n",
      "\n",
      "Iteration 2400, loss = 0.9222\n",
      "Got 2268 / 3000 correct (75.60)\n",
      "\n",
      "Iteration 2500, loss = 0.5055\n",
      "Got 2334 / 3000 correct (77.80)\n",
      "\n",
      "Iteration 2600, loss = 0.9842\n",
      "Got 2274 / 3000 correct (75.80)\n",
      "\n",
      "Iteration 2700, loss = 0.5143\n",
      "Got 2474 / 3000 correct (82.47)\n",
      "\n",
      "Iteration 2800, loss = 0.2109\n",
      "Got 2262 / 3000 correct (75.40)\n",
      "\n",
      "Iteration 2900, loss = 0.4224\n",
      "Got 2421 / 3000 correct (80.70)\n",
      "\n",
      "Iteration 3000, loss = 0.5048\n",
      "Got 2460 / 3000 correct (82.00)\n",
      "\n",
      "Iteration 3100, loss = 0.7164\n",
      "Got 2401 / 3000 correct (80.03)\n",
      "\n",
      "Iteration 3200, loss = 0.4188\n",
      "Got 2412 / 3000 correct (80.40)\n",
      "\n",
      "Iteration 3300, loss = 0.2747\n",
      "Got 2528 / 3000 correct (84.27)\n",
      "\n",
      "Iteration 3400, loss = 0.7324\n",
      "Got 2465 / 3000 correct (82.17)\n",
      "\n",
      "Iteration 3500, loss = 0.2370\n",
      "Got 2477 / 3000 correct (82.57)\n",
      "\n",
      "Iteration 3600, loss = 0.3634\n",
      "Got 2325 / 3000 correct (77.50)\n",
      "\n",
      "Iteration 3700, loss = 0.5723\n",
      "Got 2549 / 3000 correct (84.97)\n",
      "\n",
      "Iteration 3800, loss = 0.4942\n",
      "Got 2561 / 3000 correct (85.37)\n",
      "\n",
      "Iteration 3900, loss = 0.1888\n",
      "Got 2380 / 3000 correct (79.33)\n",
      "\n",
      "Iteration 4000, loss = 0.4838\n",
      "Got 2510 / 3000 correct (83.67)\n",
      "\n",
      "Iteration 4100, loss = 0.3094\n",
      "Got 2470 / 3000 correct (82.33)\n",
      "\n",
      "Iteration 4200, loss = 0.3438\n",
      "Got 2568 / 3000 correct (85.60)\n",
      "\n",
      "Iteration 0, loss = 0.2598\n",
      "Got 2515 / 3000 correct (83.83)\n",
      "\n",
      "Iteration 100, loss = 0.4384\n",
      "Got 2564 / 3000 correct (85.47)\n",
      "\n",
      "Iteration 200, loss = 0.1968\n",
      "Got 2598 / 3000 correct (86.60)\n",
      "\n",
      "Iteration 300, loss = 0.0554\n",
      "Got 2582 / 3000 correct (86.07)\n",
      "\n",
      "Iteration 400, loss = 0.5858\n",
      "Got 2323 / 3000 correct (77.43)\n",
      "\n",
      "Iteration 500, loss = 0.8061\n",
      "Got 2530 / 3000 correct (84.33)\n",
      "\n",
      "Iteration 600, loss = 0.4067\n",
      "Got 2435 / 3000 correct (81.17)\n",
      "\n",
      "Iteration 700, loss = 0.1755\n",
      "Got 2550 / 3000 correct (85.00)\n",
      "\n",
      "Iteration 800, loss = 0.3319\n",
      "Got 2574 / 3000 correct (85.80)\n",
      "\n",
      "Iteration 900, loss = 0.1400\n",
      "Got 2559 / 3000 correct (85.30)\n",
      "\n",
      "Iteration 1000, loss = 0.3177\n",
      "Got 2435 / 3000 correct (81.17)\n",
      "\n",
      "Iteration 1100, loss = 0.4075\n",
      "Got 2518 / 3000 correct (83.93)\n",
      "\n",
      "Iteration 1200, loss = 0.3660\n",
      "Got 2497 / 3000 correct (83.23)\n",
      "\n",
      "Iteration 1300, loss = 0.1517\n",
      "Got 2611 / 3000 correct (87.03)\n",
      "\n",
      "Iteration 1400, loss = 0.2544\n",
      "Got 2613 / 3000 correct (87.10)\n",
      "\n",
      "Iteration 1500, loss = 0.1618\n",
      "Got 2579 / 3000 correct (85.97)\n",
      "\n",
      "Iteration 1600, loss = 0.4585\n",
      "Got 2471 / 3000 correct (82.37)\n",
      "\n",
      "Iteration 1700, loss = 0.5146\n",
      "Got 2573 / 3000 correct (85.77)\n",
      "\n",
      "Iteration 1800, loss = 0.4536\n",
      "Got 2633 / 3000 correct (87.77)\n",
      "\n",
      "Iteration 1900, loss = 0.4546\n",
      "Got 2560 / 3000 correct (85.33)\n",
      "\n",
      "Iteration 2000, loss = 0.5780\n",
      "Got 2630 / 3000 correct (87.67)\n",
      "\n",
      "Iteration 2100, loss = 0.2198\n",
      "Got 2613 / 3000 correct (87.10)\n",
      "\n",
      "Iteration 2200, loss = 0.2736\n",
      "Got 2604 / 3000 correct (86.80)\n",
      "\n",
      "Iteration 2300, loss = 0.6187\n",
      "Got 2634 / 3000 correct (87.80)\n",
      "\n",
      "Iteration 2400, loss = 0.5372\n",
      "Got 2592 / 3000 correct (86.40)\n",
      "\n",
      "Iteration 2500, loss = 0.0584\n",
      "Got 2611 / 3000 correct (87.03)\n",
      "\n",
      "Iteration 2600, loss = 1.2130\n",
      "Got 2661 / 3000 correct (88.70)\n",
      "\n",
      "Iteration 2700, loss = 0.0427\n",
      "Got 2522 / 3000 correct (84.07)\n",
      "\n",
      "Iteration 2800, loss = 0.5236\n",
      "Got 2572 / 3000 correct (85.73)\n",
      "\n",
      "Iteration 2900, loss = 0.3448\n",
      "Got 2557 / 3000 correct (85.23)\n",
      "\n",
      "Iteration 3000, loss = 0.5856\n",
      "Got 2560 / 3000 correct (85.33)\n",
      "\n",
      "Iteration 3100, loss = 0.2966\n",
      "Got 2657 / 3000 correct (88.57)\n",
      "\n",
      "Iteration 3200, loss = 0.3708\n",
      "Got 2491 / 3000 correct (83.03)\n",
      "\n",
      "Iteration 3300, loss = 0.0781\n",
      "Got 2586 / 3000 correct (86.20)\n",
      "\n",
      "Iteration 3400, loss = 0.0649\n",
      "Got 2661 / 3000 correct (88.70)\n",
      "\n",
      "Iteration 3500, loss = 1.2677\n",
      "Got 2659 / 3000 correct (88.63)\n",
      "\n",
      "Iteration 3600, loss = 0.1297\n",
      "Got 2606 / 3000 correct (86.87)\n",
      "\n",
      "Iteration 3700, loss = 0.3691\n",
      "Got 2662 / 3000 correct (88.73)\n",
      "\n",
      "Iteration 3800, loss = 0.2144\n",
      "Got 2673 / 3000 correct (89.10)\n",
      "\n",
      "Iteration 3900, loss = 0.7003\n",
      "Got 2417 / 3000 correct (80.57)\n",
      "\n",
      "Iteration 4000, loss = 0.0800\n",
      "Got 2555 / 3000 correct (85.17)\n",
      "\n",
      "Iteration 4100, loss = 0.4890\n",
      "Got 2621 / 3000 correct (87.37)\n",
      "\n",
      "Iteration 4200, loss = 0.4699\n",
      "Got 2649 / 3000 correct (88.30)\n",
      "\n",
      "Iteration 0, loss = 0.3602\n",
      "Got 2633 / 3000 correct (87.77)\n",
      "\n",
      "Iteration 100, loss = 0.6128\n",
      "Got 2506 / 3000 correct (83.53)\n",
      "\n",
      "Iteration 200, loss = 0.0098\n",
      "Got 2653 / 3000 correct (88.43)\n",
      "\n",
      "Iteration 300, loss = 0.8036\n",
      "Got 2594 / 3000 correct (86.47)\n",
      "\n",
      "Iteration 400, loss = 0.2859\n",
      "Got 2694 / 3000 correct (89.80)\n",
      "\n",
      "Iteration 500, loss = 0.7692\n",
      "Got 2616 / 3000 correct (87.20)\n",
      "\n",
      "Iteration 600, loss = 0.3587\n",
      "Got 2673 / 3000 correct (89.10)\n",
      "\n",
      "Iteration 700, loss = 0.8574\n",
      "Got 2627 / 3000 correct (87.57)\n",
      "\n",
      "Iteration 800, loss = 0.2705\n",
      "Got 2512 / 3000 correct (83.73)\n",
      "\n",
      "Iteration 900, loss = 0.7163\n",
      "Got 2631 / 3000 correct (87.70)\n",
      "\n",
      "Iteration 1000, loss = 0.0223\n",
      "Got 2605 / 3000 correct (86.83)\n",
      "\n",
      "Iteration 1100, loss = 0.1571\n",
      "Got 2682 / 3000 correct (89.40)\n",
      "\n",
      "Iteration 1200, loss = 0.3164\n",
      "Got 2611 / 3000 correct (87.03)\n",
      "\n",
      "Iteration 1300, loss = 0.3398\n",
      "Got 2687 / 3000 correct (89.57)\n",
      "\n",
      "Iteration 1400, loss = 0.2869\n",
      "Got 2652 / 3000 correct (88.40)\n",
      "\n",
      "Iteration 1500, loss = 0.0698\n",
      "Got 2703 / 3000 correct (90.10)\n",
      "\n",
      "Iteration 1600, loss = 0.0330\n",
      "Got 2484 / 3000 correct (82.80)\n",
      "\n",
      "Iteration 1700, loss = 0.6265\n",
      "Got 2492 / 3000 correct (83.07)\n",
      "\n",
      "Iteration 1800, loss = 0.3860\n",
      "Got 2618 / 3000 correct (87.27)\n",
      "\n",
      "Iteration 1900, loss = 0.7790\n",
      "Got 2592 / 3000 correct (86.40)\n",
      "\n",
      "Iteration 2000, loss = 0.6353\n",
      "Got 2599 / 3000 correct (86.63)\n",
      "\n",
      "Iteration 2100, loss = 0.0325\n",
      "Got 2665 / 3000 correct (88.83)\n",
      "\n",
      "Iteration 2200, loss = 0.1799\n",
      "Got 2550 / 3000 correct (85.00)\n",
      "\n",
      "Iteration 2300, loss = 0.0860\n",
      "Got 2563 / 3000 correct (85.43)\n",
      "\n",
      "Iteration 2400, loss = 0.4146\n",
      "Got 2674 / 3000 correct (89.13)\n",
      "\n",
      "Iteration 2500, loss = 0.1583\n",
      "Got 2583 / 3000 correct (86.10)\n",
      "\n",
      "Iteration 2600, loss = 0.6366\n",
      "Got 2689 / 3000 correct (89.63)\n",
      "\n",
      "Iteration 2700, loss = 0.0066\n",
      "Got 2556 / 3000 correct (85.20)\n",
      "\n",
      "Iteration 2800, loss = 0.0989\n",
      "Got 2505 / 3000 correct (83.50)\n",
      "\n",
      "Iteration 2900, loss = 0.3448\n",
      "Got 2688 / 3000 correct (89.60)\n",
      "\n",
      "Iteration 3000, loss = 0.0697\n",
      "Got 2675 / 3000 correct (89.17)\n",
      "\n",
      "Iteration 3100, loss = 0.0007\n",
      "Got 2355 / 3000 correct (78.50)\n",
      "\n",
      "Iteration 3200, loss = 0.2177\n",
      "Got 2693 / 3000 correct (89.77)\n",
      "\n",
      "Iteration 3300, loss = 0.0396\n",
      "Got 2646 / 3000 correct (88.20)\n",
      "\n",
      "Iteration 3400, loss = 0.1568\n",
      "Got 2669 / 3000 correct (88.97)\n",
      "\n",
      "Iteration 3500, loss = 0.0062\n",
      "Got 2689 / 3000 correct (89.63)\n",
      "\n",
      "Iteration 3600, loss = 0.1977\n",
      "Got 2630 / 3000 correct (87.67)\n",
      "\n",
      "Iteration 3700, loss = 0.0109\n",
      "Got 2457 / 3000 correct (81.90)\n",
      "\n",
      "Iteration 3800, loss = 0.0759\n",
      "Got 2684 / 3000 correct (89.47)\n",
      "\n",
      "Iteration 3900, loss = 0.1467\n",
      "Got 2658 / 3000 correct (88.60)\n",
      "\n",
      "Iteration 4000, loss = 0.3316\n",
      "Got 2521 / 3000 correct (84.03)\n",
      "\n",
      "Iteration 4100, loss = 0.9530\n",
      "Got 2704 / 3000 correct (90.13)\n",
      "\n",
      "Iteration 4200, loss = 0.0743\n",
      "Got 2700 / 3000 correct (90.00)\n",
      "\n",
      "Iteration 0, loss = 0.3057\n",
      "Got 2688 / 3000 correct (89.60)\n",
      "\n",
      "Iteration 100, loss = 0.0063\n",
      "Got 2676 / 3000 correct (89.20)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200, loss = 0.6557\n",
      "Got 2660 / 3000 correct (88.67)\n",
      "\n",
      "Iteration 300, loss = 0.3935\n",
      "Got 2596 / 3000 correct (86.53)\n",
      "\n",
      "Iteration 400, loss = 0.5363\n",
      "Got 2700 / 3000 correct (90.00)\n",
      "\n",
      "Iteration 500, loss = 0.1738\n",
      "Got 2709 / 3000 correct (90.30)\n",
      "\n",
      "Iteration 600, loss = 0.3501\n",
      "Got 2409 / 3000 correct (80.30)\n",
      "\n",
      "Iteration 700, loss = 0.0441\n",
      "Got 2604 / 3000 correct (86.80)\n",
      "\n",
      "Iteration 800, loss = 0.0317\n",
      "Got 2743 / 3000 correct (91.43)\n",
      "\n",
      "Iteration 900, loss = 0.1796\n",
      "Got 2694 / 3000 correct (89.80)\n",
      "\n",
      "Iteration 1000, loss = 0.2452\n",
      "Got 2684 / 3000 correct (89.47)\n",
      "\n",
      "Iteration 1100, loss = 0.0054\n",
      "Got 2742 / 3000 correct (91.40)\n",
      "\n",
      "Iteration 1200, loss = 0.5582\n",
      "Got 2630 / 3000 correct (87.67)\n",
      "\n",
      "Iteration 1300, loss = 0.3810\n",
      "Got 2720 / 3000 correct (90.67)\n",
      "\n",
      "Iteration 1400, loss = 0.0612\n",
      "Got 2623 / 3000 correct (87.43)\n",
      "\n",
      "Iteration 1500, loss = 0.1502\n",
      "Got 2680 / 3000 correct (89.33)\n",
      "\n",
      "Iteration 1600, loss = 0.0701\n",
      "Got 2715 / 3000 correct (90.50)\n",
      "\n",
      "Iteration 1700, loss = 0.7128\n",
      "Got 2690 / 3000 correct (89.67)\n",
      "\n",
      "Iteration 1800, loss = 0.0780\n",
      "Got 2715 / 3000 correct (90.50)\n",
      "\n",
      "Iteration 1900, loss = 0.4156\n",
      "Got 2626 / 3000 correct (87.53)\n",
      "\n",
      "Iteration 2000, loss = 0.0197\n",
      "Got 2637 / 3000 correct (87.90)\n",
      "\n",
      "Iteration 2100, loss = 0.4562\n",
      "Got 2690 / 3000 correct (89.67)\n",
      "\n",
      "Iteration 2200, loss = 0.0956\n",
      "Got 2688 / 3000 correct (89.60)\n",
      "\n",
      "Iteration 2300, loss = 0.4779\n",
      "Got 2658 / 3000 correct (88.60)\n",
      "\n",
      "Iteration 2400, loss = 0.2676\n",
      "Got 2686 / 3000 correct (89.53)\n",
      "\n",
      "Iteration 2500, loss = 0.1389\n",
      "Got 2722 / 3000 correct (90.73)\n",
      "\n",
      "Iteration 2600, loss = 0.4917\n",
      "Got 2708 / 3000 correct (90.27)\n",
      "\n",
      "Iteration 2700, loss = 0.3495\n",
      "Got 2585 / 3000 correct (86.17)\n",
      "\n",
      "Iteration 2800, loss = 0.4314\n",
      "Got 2541 / 3000 correct (84.70)\n",
      "\n",
      "Iteration 2900, loss = 0.1043\n",
      "Got 2746 / 3000 correct (91.53)\n",
      "\n",
      "Iteration 3000, loss = 0.2432\n",
      "Got 2523 / 3000 correct (84.10)\n",
      "\n",
      "Iteration 3100, loss = 0.2960\n",
      "Got 2739 / 3000 correct (91.30)\n",
      "\n",
      "Iteration 3200, loss = 0.0110\n",
      "Got 2747 / 3000 correct (91.57)\n",
      "\n",
      "Iteration 3300, loss = 0.8951\n",
      "Got 2759 / 3000 correct (91.97)\n",
      "\n",
      "Iteration 3400, loss = 0.3280\n",
      "Got 2745 / 3000 correct (91.50)\n",
      "\n",
      "Iteration 3500, loss = 0.1153\n",
      "Got 2695 / 3000 correct (89.83)\n",
      "\n",
      "Iteration 3600, loss = 0.2576\n",
      "Got 2649 / 3000 correct (88.30)\n",
      "\n",
      "Iteration 3700, loss = 0.1861\n",
      "Got 2725 / 3000 correct (90.83)\n",
      "\n",
      "Iteration 3800, loss = 0.6100\n",
      "Got 2723 / 3000 correct (90.77)\n",
      "\n",
      "Iteration 3900, loss = 0.0687\n",
      "Got 2749 / 3000 correct (91.63)\n",
      "\n",
      "Iteration 4000, loss = 0.2435\n",
      "Got 2684 / 3000 correct (89.47)\n",
      "\n",
      "Iteration 4100, loss = 0.0557\n",
      "Got 2696 / 3000 correct (89.87)\n",
      "\n",
      "Iteration 4200, loss = 1.0171\n",
      "Got 2682 / 3000 correct (89.40)\n",
      "\n",
      "Iteration 0, loss = 0.2609\n",
      "Got 2756 / 3000 correct (91.87)\n",
      "\n",
      "Iteration 100, loss = 0.0903\n",
      "Got 2725 / 3000 correct (90.83)\n",
      "\n",
      "Iteration 200, loss = 0.1697\n",
      "Got 2750 / 3000 correct (91.67)\n",
      "\n",
      "Iteration 300, loss = 0.5222\n",
      "Got 2692 / 3000 correct (89.73)\n",
      "\n",
      "Iteration 400, loss = 0.5679\n",
      "Got 2681 / 3000 correct (89.37)\n",
      "\n",
      "Iteration 500, loss = 0.4621\n",
      "Got 2762 / 3000 correct (92.07)\n",
      "\n",
      "Iteration 600, loss = 0.6283\n",
      "Got 2734 / 3000 correct (91.13)\n",
      "\n",
      "Iteration 700, loss = 0.3259\n",
      "Got 2747 / 3000 correct (91.57)\n",
      "\n",
      "Iteration 800, loss = 0.1580\n",
      "Got 2759 / 3000 correct (91.97)\n",
      "\n",
      "Iteration 900, loss = 0.2862\n",
      "Got 2716 / 3000 correct (90.53)\n",
      "\n",
      "Iteration 1000, loss = 0.1164\n",
      "Got 2764 / 3000 correct (92.13)\n",
      "\n",
      "Iteration 1100, loss = 0.0022\n",
      "Got 2695 / 3000 correct (89.83)\n",
      "\n",
      "Iteration 1200, loss = 0.2264\n",
      "Got 2767 / 3000 correct (92.23)\n",
      "\n",
      "Iteration 1300, loss = 0.0129\n",
      "Got 2717 / 3000 correct (90.57)\n",
      "\n",
      "Iteration 1400, loss = 0.1338\n",
      "Got 2687 / 3000 correct (89.57)\n",
      "\n",
      "Iteration 1500, loss = 0.5831\n",
      "Got 2759 / 3000 correct (91.97)\n",
      "\n",
      "Iteration 1600, loss = 0.8241\n",
      "Got 2601 / 3000 correct (86.70)\n",
      "\n",
      "Iteration 1700, loss = 0.0271\n",
      "Got 2736 / 3000 correct (91.20)\n",
      "\n",
      "Iteration 1800, loss = 0.0176\n",
      "Got 2784 / 3000 correct (92.80)\n",
      "\n",
      "Iteration 1900, loss = 0.0964\n",
      "Got 2674 / 3000 correct (89.13)\n",
      "\n",
      "Iteration 2000, loss = 0.1476\n",
      "Got 2747 / 3000 correct (91.57)\n",
      "\n",
      "Iteration 2100, loss = 0.3625\n",
      "Got 2738 / 3000 correct (91.27)\n",
      "\n",
      "Iteration 2200, loss = 0.2374\n",
      "Got 2773 / 3000 correct (92.43)\n",
      "\n",
      "Iteration 2300, loss = 0.4255\n",
      "Got 2701 / 3000 correct (90.03)\n",
      "\n",
      "Iteration 2400, loss = 0.0850\n",
      "Got 2746 / 3000 correct (91.53)\n",
      "\n",
      "Iteration 2500, loss = 0.1546\n",
      "Got 2767 / 3000 correct (92.23)\n",
      "\n",
      "Iteration 2600, loss = 0.2171\n",
      "Got 2636 / 3000 correct (87.87)\n",
      "\n",
      "Iteration 2700, loss = 0.2386\n",
      "Got 2558 / 3000 correct (85.27)\n",
      "\n",
      "Iteration 2800, loss = 0.0072\n",
      "Got 2732 / 3000 correct (91.07)\n",
      "\n",
      "Iteration 2900, loss = 0.1150\n",
      "Got 2690 / 3000 correct (89.67)\n",
      "\n",
      "Iteration 3000, loss = 0.1157\n",
      "Got 2682 / 3000 correct (89.40)\n",
      "\n",
      "Iteration 3100, loss = 0.0658\n",
      "Got 2667 / 3000 correct (88.90)\n",
      "\n",
      "Iteration 3200, loss = 0.2043\n",
      "Got 2776 / 3000 correct (92.53)\n",
      "\n",
      "Iteration 3300, loss = 0.2458\n",
      "Got 2783 / 3000 correct (92.77)\n",
      "\n",
      "Iteration 3400, loss = 0.2525\n",
      "Got 2778 / 3000 correct (92.60)\n",
      "\n",
      "Iteration 3500, loss = 0.5200\n",
      "Got 2786 / 3000 correct (92.87)\n",
      "\n",
      "Iteration 3600, loss = 1.0164\n",
      "Got 2710 / 3000 correct (90.33)\n",
      "\n",
      "Iteration 3700, loss = 0.1549\n",
      "Got 2672 / 3000 correct (89.07)\n",
      "\n",
      "Iteration 3800, loss = 0.1340\n",
      "Got 2753 / 3000 correct (91.77)\n",
      "\n",
      "Iteration 3900, loss = 0.0384\n",
      "Got 2785 / 3000 correct (92.83)\n",
      "\n",
      "Iteration 4000, loss = 0.0407\n",
      "Got 2759 / 3000 correct (91.97)\n",
      "\n",
      "Iteration 4100, loss = 0.0523\n",
      "Got 2707 / 3000 correct (90.23)\n",
      "\n",
      "Iteration 4200, loss = 0.1855\n",
      "Got 2634 / 3000 correct (87.80)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_1 = 32 \n",
    "channel_2 = 16\n",
    "learning_rate = 1e-4\n",
    "model = None \n",
    "optimizer = None \n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv1d(3, 32, 3, stride = 1, padding = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(32, 64, 2, stride = 2, padding = 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(64, 128, 5, stride = 1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(1408, 4)\n",
    ")\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9, nesterov = True)\n",
    "train_part34(model, optimizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LocationDataset(test_splot, test_lable)\n",
    "loader_test = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 7912 / 8633 correct (91.65)\n",
      "查准率0.9131808183256229\n",
      "召回率0.9144474151250588\n",
      "F1分数0.916356066372306\n",
      "混淆矩阵\n",
      "[[2573    7    7   28]\n",
      " [   0 1817    2   55]\n",
      " [  39   26 1616  170]\n",
      " [  36   16  335 1906]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9131808183256229"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(loader,model):\n",
    "    num_correct = 0 \n",
    "    num_samples = 0 \n",
    "    res = []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device=device, dtype=dtype)\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "        scores = model(x)\n",
    "        _, preds = scores.max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "        res.append(preds.item())\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return res\n",
    "\n",
    "\n",
    "res = test(loader_test,model)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "def gradeOfClassifier():\n",
    "    P = metrics.precision_score(test_lable, res, average='macro')\n",
    "    R = metrics.recall_score(test_lable, res, average='macro')\n",
    "    # F1分数\n",
    "    F1 = metrics.f1_score(test_lable, res, average='weighted')\n",
    "    # 混淆矩阵\n",
    "    M = metrics.confusion_matrix(test_lable, res, labels=[0.0, 1.0, 2.0, 3.0])\n",
    "    print(\"查准率\" + str(P))\n",
    "    print(\"召回率\" + str(R))\n",
    "    print(\"F1分数\" + str(F1))\n",
    "    print(\"混淆矩阵\")\n",
    "    print(M)\n",
    "    print()\n",
    "    return P\n",
    "gradeOfClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lys.filter.examples.sine_wave import kalmanfilter\n",
    "from lys.filter.movinAverage import MoveAverage\n",
    "from lys.filter.sampleFilter import last_polyfit\n",
    "from lys.evaluate import getMae, Mape, Rmse\n",
    "\n",
    "def classifer(model, splot, path):\n",
    "    resultSeqStatic = []  # 静止状态\n",
    "    resultSeqUnrealized = []  # 无意识运动状态\n",
    "    resultSeqBackMove = []  # 短距离往返运动\n",
    "    resultSeqforward = []  # 长距离往返运动\n",
    "    splotre = []\n",
    "    # 运动状态分析，与剔除\n",
    "    with open(path, 'r') as f:\n",
    "        obj = []\n",
    "        flag = False  # 是否第一次记录起始时间\n",
    "        start = ''  # 当前子序列的起始时间\n",
    "        for s in f.readlines():  # 按行读取数据\n",
    "            if len(s) <= 1:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                s = s[:-1]\n",
    "                seq = s.split(\" \")\n",
    "                if flag == False :\n",
    "                    #本数据序列第一点的采集时间\n",
    "                    start = 0\n",
    "                    now = 0\n",
    "                    flag = True \n",
    "                # 当前点的采集时间\n",
    "                now = now + 1\n",
    "                subt = now - start \n",
    "                myseq = [seq[1][7:], seq[2][7:], seq[3][7:]]\n",
    "                obj.append(np.asarray(myseq,dtype='float64'))\n",
    "            if subt > splot:\n",
    "                splotre.append(np.asarray(obj))\n",
    "                obj.clear() \n",
    "                flag = False\n",
    "    splotre = np.asarray(splotre)\n",
    "    for plot in splotre:\n",
    "        tensor = torch.FloatTensor(plot.T)\n",
    "        tensor = tensor.view((1,3,20))\n",
    "        scores = model(tensor)\n",
    "        _, state = scores.max(1)\n",
    "        if state.item() == 0:\n",
    "            resultSeqStatic += plot.tolist()\n",
    "        elif state.item() == 1:\n",
    "            resultSeqUnrealized += plot.tolist()\n",
    "        elif state.item() == 2:\n",
    "            resultSeqBackMove += plot.tolist()\n",
    "        elif state.item() == 3:\n",
    "            resultSeqforward += plot.tolist()\n",
    "    return resultSeqStatic, resultSeqUnrealized, resultSeqBackMove, resultSeqforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countdistance(seq):\n",
    "    distance = 0.0\n",
    "    # 计算一个序列的运动距离\n",
    "    if len(seq) <= 1:  # 只有一个点时，距离为零\n",
    "        return distance\n",
    "    else:\n",
    "        p1 = seq[0]  # 轨迹的第一个点\n",
    "        for value in seq[1:]:\n",
    "            p2 = value\n",
    "            d = np.sqrt((float(p1[0]) - float(p2[0])) ** 2 + (float(p1[1]) - float(p2[1])) ** 2)  # 两点间的距离\n",
    "            if d < 2.0:\n",
    "                distance += d\n",
    "            p1 = p2\n",
    "        distance = float(\"%.2f\" % distance)\n",
    "        return distance\n",
    "\n",
    "\n",
    "# 卡尔曼滤波器\n",
    "def kalmanFilter(seq):\n",
    "    x_value = []\n",
    "    y_value = []\n",
    "    for i in range(len(seq)):\n",
    "        temp = seq[i]\n",
    "        x_value.append(float(temp[0]))\n",
    "        y_value.append(float(temp[1]))\n",
    "    x_value = kalmanfilter(x_value, len(x_value))  # 滤波\n",
    "\n",
    "    length = min(len(x_value), len(y_value))  # 数组长度\n",
    "    sequence = [[x_value[i], y_value[i]] for i in range(0, length)]\n",
    "    return sequence\n",
    "\n",
    "\n",
    "# 最小二乘法拟合多项式\n",
    "def leastfit(seq):\n",
    "    result = last_polyfit(seq)\n",
    "    return result\n",
    "\n",
    "\n",
    "def MovingAverage(seq):\n",
    "    obj = MoveAverage(seq, 11)  # 创建对象\n",
    "    result = obj.smooth()  # 平滑数据\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.94\n",
      "47.38\n",
      "1762.6\n",
      "2103.82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3913.8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirPath = \"D:\\\\fig\\\\test\\\\data\"\n",
    "path = [dirPath + '\\\\' + x for x in os.listdir(dirPath)]\n",
    "resultSeqStatic, resultSeqUnrealized, resultSeqBackMove, resultSeqforward = classifer(model, 19, path[3])\n",
    "print(countdistance(resultSeqStatic))\n",
    "print(countdistance(resultSeqUnrealized))\n",
    "print(countdistance(resultSeqBackMove))\n",
    "print(countdistance(resultSeqforward))\n",
    "countdistance(resultSeqBackMove) + countdistance(resultSeqUnrealized) + countdistance(resultSeqforward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index=1  卡尔曼滤波\n",
    "# index=2  最小二乘\n",
    "# index=1  滑动均值\n",
    "def deal(index, seq):\n",
    "    if index == 1:\n",
    "        return kalmanFilter(seq)\n",
    "    elif index == 2:\n",
    "        return leastfit(seq)\n",
    "    elif index == 3:\n",
    "        return MovingAverage(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对不同状态的数据处理\n",
    "def fn(i, j, k, classfilter, slot, path):\n",
    "    re = []\n",
    "    for p in path:\n",
    "        # 各状态下的轨迹\n",
    "        resultSeqStatic, resultSeqUnrealized, resultSeqBackMove, resultSeqforward = classifer(classfilter,\n",
    "                                                                                              slot, p)\n",
    "        # #除去静止状态后，在拟合处理数据的轨迹的距离\n",
    "        d1 = countdistance(deal(i, resultSeqUnrealized))\n",
    "        d2 = countdistance(deal(j, resultSeqBackMove))\n",
    "        d3 = countdistance(deal(k, resultSeqforward))\n",
    "        distance2 = d1 + d2 + d3\n",
    "        re.append(distance2)\n",
    "    return re\n",
    "\n",
    "\n",
    "def draw2(title, measure, trueValue):\n",
    "    plt.figure(title)\n",
    "    x = [i for i in range(1, 13)]\n",
    "    plt.xlabel('轨迹序号', fontproperties='SimHei', fontsize=10)\n",
    "    plt.ylabel('轨迹长度(米)', fontproperties='SimHei', fontsize=10)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.plot(x, measure, marker='+', linestyle='--', label='1d-CNN')  # 计算值\n",
    "\n",
    "    plt.plot(x, trueValue, marker='o', linestyle='-', label='真实距离')  # 真值\n",
    "    plt.legend(loc='lower right')  # label生效\n",
    "    plt.xticks(x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main2(slot):\n",
    "    dirPath = \"D:\\\\项目\\\\廖煜胜-论文\\\\论文\\\\数据与程序\\\\datacollect\\\\test\\\\data\"\n",
    "    path = [dirPath + '\\\\' + x for x in os.listdir(dirPath)]\n",
    "    i = 1\n",
    "    j = 2\n",
    "    k = 1\n",
    "    re = fn(i, j, k, model, slot, path)\n",
    "\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvalue(path):\n",
    "    f = open(path, \"r\")  # 源文件\n",
    "    result = []\n",
    "    for s in f.readlines():\n",
    "        num = float(s.split(\"  \")[1][:-1])\n",
    "        result.append(num)\n",
    "    return result\n",
    "\n",
    "\n",
    "# 求和\n",
    "def distanceofseq(value):\n",
    "    val_sum = 0\n",
    "    for i in range(len(value)):\n",
    "        val_sum += float(value[i])\n",
    "    return val_sum\n",
    "\n",
    "\n",
    "def SD(measure, value):\n",
    "    d = 0  # 标准差\n",
    "    err = 0  # 平均误差\n",
    "    sum_value = 0\n",
    "    sum_measure = 0\n",
    "    for i in range(len(value)):\n",
    "        d = d + (value[i] - measure[i]) ** 2\n",
    "        err += measure[i] - value[i]\n",
    "        sum_value += value[i]\n",
    "        sum_measure += measure[i]\n",
    "\n",
    "    d = np.sqrt(d) / len(value)\n",
    "    err = err / len(value)\n",
    "    ff = (sum_measure - sum_value) / sum_value\n",
    "\n",
    "    print(\"误差： \" + str(err))\n",
    "    print(\"相对误差率： \" + str(ff))\n",
    "    print(\"标准差： \" + str(d))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\fig\\lys\\filter\\examples\\sine_wave.py:67: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\fig\\lys\\filter\\examples\\tfkalman\\filters.py:42: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\fig\\lys\\filter\\examples\\tfkalman\\filters.py:68: The name tf.matrix_inverse is deprecated. Please use tf.linalg.inv instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\fig\\lys\\filter\\examples\\sine_wave.py:71: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "平均绝对值误差：19.860000000000003\n",
      "\n",
      "平均相对误差：0.055350250498615416\n",
      "\n",
      "均方根差：272.0805841106638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"D:\\\\项目\\\\廖煜胜-论文\\\\论文\\\\数据与程序\\\\datacollect\\\\test\\\\truevalue.txt\"\n",
    "value = getvalue(path)  # 真值\n",
    "measure = main2(19)\n",
    "getMae(measure, value)\n",
    "Mape(measure, value)\n",
    "Rmse(measure, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw4(title, measure, trueValue, label):\n",
    "    plt.figure(title)\n",
    "    x = [i for i in range(1, 13)]\n",
    "    plt.xlabel('轨迹序号', fontproperties='SimHei', fontsize=10)\n",
    "    plt.ylabel('轨迹长度（米）', fontproperties='SimHei', fontsize=10)\n",
    "    plt.title(\"计算值与真实值对比\")\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.15)  # 图边距t\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.xticks(x)\n",
    "    for i in range(1, len(x)):\n",
    "        d = ((measure[i] - trueValue[i]) / trueValue[i]) * 100\n",
    "        text = float(\"%.2f\" % d)\n",
    "        plt.text(x[i] - 0.4, measure[i] + 30, str(text) + \"%\", fontdict={'size': '10'})\n",
    "\n",
    "    plt.plot(x, measure, marker='*', linestyle='-.', label=label)  # 计算值\n",
    "    plt.plot(x, trueValue, marker='o', linestyle='-', label='真实值')  # 真值\n",
    "    plt.legend(loc='lower right')  # label生效\n",
    "    plt.savefig(\"D:\\\\fig\\\\picture\\\\\" + str(title) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw4(\"1d-cnn\", measure, value, \"1d-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
