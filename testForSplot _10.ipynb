{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision import transforms, utils\n",
    "import os\n",
    "import datetime \n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "##文件数据行为: x   y   z  time     ；表示一个坐标点的三个坐标分量和 采集时间 ，使用空格符分隔\n",
    "\n",
    "def pre(source, distance, diantance1):\n",
    "    f = open(source, \"r\")  # 源文件\n",
    "    fwrit = open(distance, \"a\")  # 卡2068\n",
    "    for s in f.readlines():\n",
    "        if len(s) == 1:\n",
    "            fwrit.write(s)\n",
    "        else:\n",
    "            s = s[:-1]\n",
    "            tem = s.split()\n",
    "            re = tem[1].split(':')[1] + \"\\t\" + tem[2].split(':')[1] + \"\\t\" + tem[3].split(':')[1] + \"\\t\" + tem[-2] + \"\\t\" + tem[-1] + \"\\n\"\n",
    "            # if tem[0] != \"2068\":\n",
    "            #     fwrit1.write(re)\n",
    "            # else:\n",
    "            if tem[0] == \"2068\":\n",
    "                fwrit.write(re)\n",
    "    f.close()\n",
    "    fwrit.close()\n",
    "\n",
    "\n",
    "def file_name(file_dir, target, target1):\n",
    "    path = [file_dir + '\\\\' + x for x in os.listdir(file_dir)]\n",
    "    for p in path:\n",
    "        if not os.path.isdir(p):\n",
    "            pre(p, target, target1)\n",
    "\n",
    "def split_data(splot):\n",
    "    \"\"\"\n",
    "    按照plot划分时间段\n",
    "    \"\"\"\n",
    "    state = \"D:\\\\fig\\\\data\\\\pre2068Static.txt\"\n",
    "    unrealize = \"D:\\\\fig\\\\data\\\\pre2068Unrealize.txt\"\n",
    "    Sactive = \"D:\\\\fig\\\\data\\\\pre2068Little.txt\"\n",
    "    Mactive = \"D:\\\\fig\\\\data\\\\pre2068LargeMove.txt\"\n",
    "    files = [state, unrealize, Sactive, Mactive]\n",
    "    mask = [0., 1., 2., 3.]\n",
    "    splotre = []\n",
    "    lable = [] \n",
    "    for index, file in enumerate(files):\n",
    "        f = open(file, \"r\")\n",
    "        mk = mask[index]\n",
    "\n",
    "        flag = False \n",
    "        start = ''\n",
    "        obj = [] \n",
    "        for s in f.readlines():\n",
    "            if len(s) <= 1:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                s = s[:-1]\n",
    "                seq = s.split(\"\\t\")\n",
    "                if flag == False :\n",
    "                    #本数据序列第一点的采集时间\n",
    "                    start = 0\n",
    "                    now = 0\n",
    "                    flag = True \n",
    "                # 当前点的采集时间\n",
    "                now = now + 1\n",
    "                subt = now - start \n",
    "                obj.append(np.asarray(seq[:3],dtype='float64'))\n",
    "            if subt > splot:\n",
    "                splotre.append(np.asarray(obj))\n",
    "                lable.append(mk)\n",
    "                obj.clear() \n",
    "                flag = False\n",
    "    splotre = np.asarray(splotre)\n",
    "    lable = np.asarray(lable)\n",
    "    return splotre, lable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大幅度运动 原始数据源\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\active\"\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068LargeMove.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preLargeMove.txt\"  # 其他卡的处理结果\n",
    "\n",
    "file_name(p, t, t1)\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\little\"  # 原始数据源\n",
    "\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Little.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preLittle.txt\"  # 其他卡的处理结果\n",
    "\n",
    "file_name(p, t, t1)\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\static\"  # 原始数据源\n",
    "\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Static.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preStatic.txt\"  # 其他卡的处理结果\n",
    "file_name(p, t, t1)\n",
    "# 无意识运动，如转身，手摆动\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\unrealize\"  # 原始数据源\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Unrealize.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preUnrealize.txt\"  # 其他卡的处理结果径\n",
    "file_name(p, t, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "splotre, lable = split_data(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19088, 30, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splotre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 3., 3., 3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 12000\n",
    "np.random.shuffle(index)\n",
    "splotre = splotre[index]\n",
    "lable = lable[index]\n",
    "train_splot = splotre[:NUM_TRAIN-3000]\n",
    "train_lable = lable[:NUM_TRAIN-3000]\n",
    "val_splot = splotre[NUM_TRAIN-3000:NUM_TRAIN]\n",
    "val_lable = lable[NUM_TRAIN-3000:NUM_TRAIN]\n",
    "test_splot = splotre[NUM_TRAIN:]\n",
    "test_lable = lable[NUM_TRAIN:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, splot):\n",
    "        return torch.from_numpy(splot)\n",
    "    \n",
    "trans = T.Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "class LocationDataset(Dataset):\n",
    "    def __init__(self, splotre, lable, transform = trans):\n",
    "        self.splotre = np.transpose(splotre, (0, 2, 1))\n",
    "        self.lable = lable \n",
    "        self.transform = transform \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.splotre)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        splot = self.splotre[idx] \n",
    "        lable = self.lable[idx]\n",
    "        tensor = trans(splot)\n",
    "        return tensor, lable\n",
    "train_dataset = LocationDataset(train_splot, train_lable)\n",
    "loader_train = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataset = LocationDataset(val_splot, val_lable)\n",
    "loader_val = DataLoader(val_dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.3320e+00,  7.3341e+00,  7.2880e+00,  7.1911e+00,  7.1709e+00,\n",
       "           7.2502e+00,  7.3349e+00,  7.4073e+00,  7.5008e+00,  7.5851e+00,\n",
       "           7.6368e+00,  7.7193e+00,  7.8462e+00,  7.8823e+00,  7.9330e+00,\n",
       "           8.0516e+00,  8.0717e+00,  8.0458e+00,  8.0339e+00,  7.9365e+00,\n",
       "           7.9232e+00,  7.9887e+00,  7.9887e+00,  7.9756e+00,  7.9348e+00,\n",
       "           7.9348e+00,  7.8910e+00,  7.7736e+00,  7.6801e+00,  7.6358e+00],\n",
       "         [ 3.1841e-01,  1.2529e-01,  7.4530e-02, -6.9990e-02, -6.0800e-02,\n",
       "          -4.4900e-03,  1.0128e-01,  2.6819e-01,  4.5018e-01,  6.4281e-01,\n",
       "           8.4811e-01,  1.0025e+00,  1.1297e+00,  1.3010e+00,  1.4925e+00,\n",
       "           1.6707e+00,  1.8937e+00,  2.0383e+00,  2.2277e+00,  2.4052e+00,\n",
       "           2.5926e+00,  2.7865e+00,  2.7865e+00,  3.1161e+00,  3.3097e+00,\n",
       "           3.3097e+00,  3.3666e+00,  3.1911e+00,  2.9938e+00,  2.7971e+00],\n",
       "         [ 1.5000e+00,  1.5000e+00,  1.5000e+00,  1.5000e+00,  1.5000e+00,\n",
       "           1.5000e+00,  1.5000e+00,  1.5000e+00,  1.5000e+00,  1.5000e+00,\n",
       "           1.5000e+00,  1.5000e+00,  1.5000e+00,  1.5000e+00,  1.5000e+00,\n",
       "           1.5000e+00,  1.5000e+00,  1.5000e+00,  1.5000e+00,  1.5000e+00,\n",
       "           1.5000e+00,  1.5000e+00,  1.5000e+00,  1.5000e+00,  1.5000e+00,\n",
       "           1.5000e+00,  1.5000e+00,  1.5000e+00,  1.5000e+00,  1.5000e+00]],\n",
       "        device='cpu', dtype=torch.float64), 2.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_val.dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = False\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F  # useful stateless functions\n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model): \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 1.4089\n",
      "Got 871 / 3000 correct (29.03)\n",
      "\n",
      "Iteration 100, loss = 1.4315\n",
      "Got 652 / 3000 correct (21.73)\n",
      "\n",
      "Iteration 200, loss = 1.3567\n",
      "Got 885 / 3000 correct (29.50)\n",
      "\n",
      "Iteration 300, loss = 1.3585\n",
      "Got 1349 / 3000 correct (44.97)\n",
      "\n",
      "Iteration 400, loss = 1.3241\n",
      "Got 1571 / 3000 correct (52.37)\n",
      "\n",
      "Iteration 500, loss = 1.2818\n",
      "Got 1580 / 3000 correct (52.67)\n",
      "\n",
      "Iteration 600, loss = 1.2061\n",
      "Got 1227 / 3000 correct (40.90)\n",
      "\n",
      "Iteration 700, loss = 1.2959\n",
      "Got 1777 / 3000 correct (59.23)\n",
      "\n",
      "Iteration 800, loss = 1.1423\n",
      "Got 1902 / 3000 correct (63.40)\n",
      "\n",
      "Iteration 900, loss = 1.2256\n",
      "Got 1925 / 3000 correct (64.17)\n",
      "\n",
      "Iteration 1000, loss = 0.9346\n",
      "Got 2174 / 3000 correct (72.47)\n",
      "\n",
      "Iteration 1100, loss = 1.4562\n",
      "Got 1729 / 3000 correct (57.63)\n",
      "\n",
      "Iteration 1200, loss = 1.4042\n",
      "Got 2135 / 3000 correct (71.17)\n",
      "\n",
      "Iteration 1300, loss = 1.2985\n",
      "Got 2151 / 3000 correct (71.70)\n",
      "\n",
      "Iteration 1400, loss = 0.6270\n",
      "Got 2231 / 3000 correct (74.37)\n",
      "\n",
      "Iteration 1500, loss = 0.9422\n",
      "Got 2249 / 3000 correct (74.97)\n",
      "\n",
      "Iteration 1600, loss = 1.0363\n",
      "Got 2193 / 3000 correct (73.10)\n",
      "\n",
      "Iteration 1700, loss = 0.5344\n",
      "Got 2252 / 3000 correct (75.07)\n",
      "\n",
      "Iteration 1800, loss = 0.3157\n",
      "Got 2153 / 3000 correct (71.77)\n",
      "\n",
      "Iteration 1900, loss = 0.7349\n",
      "Got 2182 / 3000 correct (72.73)\n",
      "\n",
      "Iteration 2000, loss = 0.5437\n",
      "Got 2161 / 3000 correct (72.03)\n",
      "\n",
      "Iteration 2100, loss = 0.7457\n",
      "Got 2469 / 3000 correct (82.30)\n",
      "\n",
      "Iteration 2200, loss = 0.2855\n",
      "Got 2498 / 3000 correct (83.27)\n",
      "\n",
      "Iteration 0, loss = 0.6266\n",
      "Got 2562 / 3000 correct (85.40)\n",
      "\n",
      "Iteration 100, loss = 0.3638\n",
      "Got 2348 / 3000 correct (78.27)\n",
      "\n",
      "Iteration 200, loss = 0.6827\n",
      "Got 2530 / 3000 correct (84.33)\n",
      "\n",
      "Iteration 300, loss = 0.7566\n",
      "Got 2562 / 3000 correct (85.40)\n",
      "\n",
      "Iteration 400, loss = 0.2073\n",
      "Got 2445 / 3000 correct (81.50)\n",
      "\n",
      "Iteration 500, loss = 0.2827\n",
      "Got 2564 / 3000 correct (85.47)\n",
      "\n",
      "Iteration 600, loss = 0.5700\n",
      "Got 2670 / 3000 correct (89.00)\n",
      "\n",
      "Iteration 700, loss = 0.0713\n",
      "Got 2511 / 3000 correct (83.70)\n",
      "\n",
      "Iteration 800, loss = 0.3685\n",
      "Got 2611 / 3000 correct (87.03)\n",
      "\n",
      "Iteration 900, loss = 0.2803\n",
      "Got 2641 / 3000 correct (88.03)\n",
      "\n",
      "Iteration 1000, loss = 0.2247\n",
      "Got 2387 / 3000 correct (79.57)\n",
      "\n",
      "Iteration 1100, loss = 0.5687\n",
      "Got 2464 / 3000 correct (82.13)\n",
      "\n",
      "Iteration 1200, loss = 0.9608\n",
      "Got 2553 / 3000 correct (85.10)\n",
      "\n",
      "Iteration 1300, loss = 0.3459\n",
      "Got 2589 / 3000 correct (86.30)\n",
      "\n",
      "Iteration 1400, loss = 0.4306\n",
      "Got 2595 / 3000 correct (86.50)\n",
      "\n",
      "Iteration 1500, loss = 0.0514\n",
      "Got 2662 / 3000 correct (88.73)\n",
      "\n",
      "Iteration 1600, loss = 0.2211\n",
      "Got 2662 / 3000 correct (88.73)\n",
      "\n",
      "Iteration 1700, loss = 0.2849\n",
      "Got 2528 / 3000 correct (84.27)\n",
      "\n",
      "Iteration 1800, loss = 0.0768\n",
      "Got 2694 / 3000 correct (89.80)\n",
      "\n",
      "Iteration 1900, loss = 0.5170\n",
      "Got 2651 / 3000 correct (88.37)\n",
      "\n",
      "Iteration 2000, loss = 0.2072\n",
      "Got 2592 / 3000 correct (86.40)\n",
      "\n",
      "Iteration 2100, loss = 0.4413\n",
      "Got 2580 / 3000 correct (86.00)\n",
      "\n",
      "Iteration 2200, loss = 0.1183\n",
      "Got 2710 / 3000 correct (90.33)\n",
      "\n",
      "Iteration 0, loss = 0.0267\n",
      "Got 2557 / 3000 correct (85.23)\n",
      "\n",
      "Iteration 100, loss = 0.0940\n",
      "Got 2703 / 3000 correct (90.10)\n",
      "\n",
      "Iteration 200, loss = 0.3021\n",
      "Got 2578 / 3000 correct (85.93)\n",
      "\n",
      "Iteration 300, loss = 0.0302\n",
      "Got 2671 / 3000 correct (89.03)\n",
      "\n",
      "Iteration 400, loss = 0.4329\n",
      "Got 2651 / 3000 correct (88.37)\n",
      "\n",
      "Iteration 500, loss = 0.3407\n",
      "Got 2695 / 3000 correct (89.83)\n",
      "\n",
      "Iteration 600, loss = 0.3914\n",
      "Got 2703 / 3000 correct (90.10)\n",
      "\n",
      "Iteration 700, loss = 0.3187\n",
      "Got 2717 / 3000 correct (90.57)\n",
      "\n",
      "Iteration 800, loss = 0.0550\n",
      "Got 2610 / 3000 correct (87.00)\n",
      "\n",
      "Iteration 900, loss = 0.0895\n",
      "Got 2717 / 3000 correct (90.57)\n",
      "\n",
      "Iteration 1000, loss = 0.1733\n",
      "Got 2541 / 3000 correct (84.70)\n",
      "\n",
      "Iteration 1100, loss = 0.2833\n",
      "Got 2719 / 3000 correct (90.63)\n",
      "\n",
      "Iteration 1200, loss = 0.0989\n",
      "Got 2672 / 3000 correct (89.07)\n",
      "\n",
      "Iteration 1300, loss = 0.1944\n",
      "Got 2717 / 3000 correct (90.57)\n",
      "\n",
      "Iteration 1400, loss = 0.4005\n",
      "Got 2672 / 3000 correct (89.07)\n",
      "\n",
      "Iteration 1500, loss = 0.0270\n",
      "Got 2615 / 3000 correct (87.17)\n",
      "\n",
      "Iteration 1600, loss = 0.2532\n",
      "Got 2677 / 3000 correct (89.23)\n",
      "\n",
      "Iteration 1700, loss = 0.0519\n",
      "Got 2665 / 3000 correct (88.83)\n",
      "\n",
      "Iteration 1800, loss = 0.5778\n",
      "Got 2734 / 3000 correct (91.13)\n",
      "\n",
      "Iteration 1900, loss = 0.0818\n",
      "Got 2661 / 3000 correct (88.70)\n",
      "\n",
      "Iteration 2000, loss = 0.0199\n",
      "Got 2723 / 3000 correct (90.77)\n",
      "\n",
      "Iteration 2100, loss = 0.8240\n",
      "Got 2582 / 3000 correct (86.07)\n",
      "\n",
      "Iteration 2200, loss = 0.3082\n",
      "Got 2657 / 3000 correct (88.57)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_1 = 32 \n",
    "channel_2 = 16\n",
    "learning_rate = 1e-4\n",
    "model = None \n",
    "optimizer = None \n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv1d(3, 32, 3, stride = 1, padding = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(32, 64, 2, stride = 2, padding = 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(64, 128, 5, stride = 1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(2048, 4)\n",
    ")\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9, nesterov = True)\n",
    "train_part34(model, optimizer, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LocationDataset(test_splot, test_lable)\n",
    "loader_test = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 6337 / 7088 correct (89.40)\n",
      "查准率0.8955945742545255\n",
      "召回率0.8950398425453393\n",
      "F1分数0.8959379616377634\n",
      "混淆矩阵\n",
      "[[1870    4  148   48]\n",
      " [   6 1511   26   30]\n",
      " [  22    9 1335  189]\n",
      " [  16   11  242 1621]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8955945742545255"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(loader,model):\n",
    "    num_correct = 0 \n",
    "    num_samples = 0 \n",
    "    res = []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device=device, dtype=dtype)\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "        scores = model(x)\n",
    "        _, preds = scores.max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "        res.append(preds.item())\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return res\n",
    "\n",
    "\n",
    "res = test(loader_test,model)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "def gradeOfClassifier():\n",
    "    P = metrics.precision_score(test_lable, res, average='macro')\n",
    "    R = metrics.recall_score(test_lable, res, average='macro')\n",
    "    # F1分数\n",
    "    F1 = metrics.f1_score(test_lable, res, average='weighted')\n",
    "    # 混淆矩阵\n",
    "    M = metrics.confusion_matrix(test_lable, res, labels=[0.0, 1.0, 2.0, 3.0])\n",
    "    print(\"查准率\" + str(P))\n",
    "    print(\"召回率\" + str(R))\n",
    "    print(\"F1分数\" + str(F1))\n",
    "    print(\"混淆矩阵\")\n",
    "    print(M)\n",
    "    print()\n",
    "    return P\n",
    "gradeOfClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lys.filter.examples.sine_wave import kalmanfilter\n",
    "from lys.filter.movinAverage import MoveAverage\n",
    "from lys.filter.sampleFilter import last_polyfit\n",
    "from lys.evaluate import getMae, Mape, Rmse\n",
    "\n",
    "def classifer(model, splot, path):\n",
    "    resultSeqStatic = []  # 静止状态\n",
    "    resultSeqUnrealized = []  # 无意识运动状态\n",
    "    resultSeqBackMove = []  # 短距离往返运动\n",
    "    resultSeqforward = []  # 长距离往返运动\n",
    "    splotre = []\n",
    "    # 运动状态分析，与剔除\n",
    "    with open(path, 'r') as f:\n",
    "        obj = []\n",
    "        flag = False  # 是否第一次记录起始时间\n",
    "        start = ''  # 当前子序列的起始时间\n",
    "        for s in f.readlines():  # 按行读取数据\n",
    "            if len(s) <= 1:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                s = s[:-1]\n",
    "                seq = s.split(\" \")\n",
    "                if flag == False :\n",
    "                    #本数据序列第一点的采集时间\n",
    "                    start = 0\n",
    "                    now = 0\n",
    "                    flag = True \n",
    "                # 当前点的采集时间\n",
    "                now = now + 1\n",
    "                subt = now - start \n",
    "                myseq = [seq[1][7:], seq[2][7:], seq[3][7:]]\n",
    "                obj.append(np.asarray(myseq,dtype='float64'))\n",
    "            if subt > splot:\n",
    "                splotre.append(np.asarray(obj))\n",
    "                obj.clear() \n",
    "                flag = False\n",
    "    splotre = np.asarray(splotre)\n",
    "    for plot in splotre:\n",
    "        tensor = torch.FloatTensor(plot.T)\n",
    "        tensor = tensor.view((1,3,30))\n",
    "        scores = model(tensor)\n",
    "        _, state = scores.max(1)\n",
    "        if state.item() == 0:\n",
    "            resultSeqStatic += plot.tolist()\n",
    "        elif state.item() == 1:\n",
    "            resultSeqUnrealized += plot.tolist()\n",
    "        elif state.item() == 2:\n",
    "            resultSeqBackMove += plot.tolist()\n",
    "        elif state.item() == 3:\n",
    "            resultSeqforward += plot.tolist()\n",
    "    return resultSeqStatic, resultSeqUnrealized, resultSeqBackMove, resultSeqforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countdistance(seq):\n",
    "    distance = 0.0\n",
    "    # 计算一个序列的运动距离\n",
    "    if len(seq) <= 1:  # 只有一个点时，距离为零\n",
    "        return distance\n",
    "    else:\n",
    "        p1 = seq[0]  # 轨迹的第一个点\n",
    "        for value in seq[1:]:\n",
    "            p2 = value\n",
    "            d = np.sqrt((float(p1[0]) - float(p2[0])) ** 2 + (float(p1[1]) - float(p2[1])) ** 2)  # 两点间的距离\n",
    "            if d < 2.0:\n",
    "                distance += d\n",
    "            p1 = p2\n",
    "        distance = float(\"%.2f\" % distance)\n",
    "        return distance\n",
    "\n",
    "\n",
    "# 卡尔曼滤波器\n",
    "def kalmanFilter(seq):\n",
    "    x_value = []\n",
    "    y_value = []\n",
    "    for i in range(len(seq)):\n",
    "        temp = seq[i]\n",
    "        x_value.append(float(temp[0]))\n",
    "        y_value.append(float(temp[1]))\n",
    "    x_value = kalmanfilter(x_value, len(x_value))  # 滤波\n",
    "\n",
    "    length = min(len(x_value), len(y_value))  # 数组长度\n",
    "    sequence = [[x_value[i], y_value[i]] for i in range(0, length)]\n",
    "    return sequence\n",
    "\n",
    "\n",
    "# 最小二乘法拟合多项式\n",
    "def leastfit(seq):\n",
    "    result = last_polyfit(seq)\n",
    "    return result\n",
    "\n",
    "\n",
    "def MovingAverage(seq):\n",
    "    obj = MoveAverage(seq, 11)  # 创建对象\n",
    "    result = obj.smooth()  # 平滑数据\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.0\n",
      "3.23\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.23"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirPath = \"D:\\\\fig\\\\test\\\\data\"\n",
    "path = [dirPath + '\\\\' + x for x in os.listdir(dirPath)]\n",
    "resultSeqStatic, resultSeqUnrealized, resultSeqBackMove, resultSeqforward = classifer(model, 29, path[0])\n",
    "print(countdistance(resultSeqStatic))\n",
    "print(countdistance(resultSeqUnrealized))\n",
    "print(countdistance(resultSeqBackMove))\n",
    "print(countdistance(resultSeqforward))\n",
    "countdistance(resultSeqBackMove) + countdistance(resultSeqUnrealized) + countdistance(resultSeqforward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index=1  卡尔曼滤波\n",
    "# index=2  最小二乘\n",
    "# index=1  滑动均值\n",
    "def deal(index, seq):\n",
    "    if index == 1:\n",
    "        return kalmanFilter(seq)\n",
    "    elif index == 2:\n",
    "        return leastfit(seq)\n",
    "    elif index == 3:\n",
    "        return MovingAverage(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对不同状态的数据处理\n",
    "def fn(i, j, k, classfilter, slot, path):\n",
    "    re = []\n",
    "    for p in path:\n",
    "        # 各状态下的轨迹\n",
    "        resultSeqStatic, resultSeqUnrealized, resultSeqBackMove, resultSeqforward = classifer(classfilter,\n",
    "                                                                                              slot, p)\n",
    "        # #除去静止状态后，在拟合处理数据的轨迹的距离\n",
    "        d1 = countdistance(deal(i, resultSeqUnrealized))\n",
    "        d2 = countdistance(deal(j, resultSeqBackMove))\n",
    "        d3 = countdistance(deal(k, resultSeqforward))\n",
    "        distance2 = d1 + d2 + d3\n",
    "        re.append(distance2)\n",
    "    return re\n",
    "\n",
    "\n",
    "def draw2(title, measure, trueValue):\n",
    "    plt.figure(title)\n",
    "    x = [i for i in range(1, 13)]\n",
    "    plt.xlabel('轨迹序号', fontproperties='SimHei', fontsize=10)\n",
    "    plt.ylabel('轨迹长度(米)', fontproperties='SimHei', fontsize=10)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.plot(x, measure, marker='+', linestyle='--', label='1d-CNN')  # 计算值\n",
    "\n",
    "    plt.plot(x, trueValue, marker='o', linestyle='-', label='真实距离')  # 真值\n",
    "    plt.legend(loc='lower right')  # label生效\n",
    "    plt.xticks(x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main2(slot):\n",
    "    dirPath = \"D:\\\\项目\\\\廖煜胜-论文\\\\论文\\\\数据与程序\\\\datacollect\\\\test\\\\data\"\n",
    "    path = [dirPath + '\\\\' + x for x in os.listdir(dirPath)]\n",
    "    i = 1\n",
    "    j = 2\n",
    "    k = 1\n",
    "    re = fn(i, j, k, model, slot, path)\n",
    "\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvalue(path):\n",
    "    f = open(path, \"r\")  # 源文件\n",
    "    result = []\n",
    "    for s in f.readlines():\n",
    "        num = float(s.split(\"  \")[1][:-1])\n",
    "        result.append(num)\n",
    "    return result\n",
    "\n",
    "\n",
    "# 求和\n",
    "def distanceofseq(value):\n",
    "    val_sum = 0\n",
    "    for i in range(len(value)):\n",
    "        val_sum += float(value[i])\n",
    "    return val_sum\n",
    "\n",
    "\n",
    "def SD(measure, value):\n",
    "    d = 0  # 标准差\n",
    "    err = 0  # 平均误差\n",
    "    sum_value = 0\n",
    "    sum_measure = 0\n",
    "    for i in range(len(value)):\n",
    "        d = d + (value[i] - measure[i]) ** 2\n",
    "        err += measure[i] - value[i]\n",
    "        sum_value += value[i]\n",
    "        sum_measure += measure[i]\n",
    "\n",
    "    d = np.sqrt(d) / len(value)\n",
    "    err = err / len(value)\n",
    "    ff = (sum_measure - sum_value) / sum_value\n",
    "\n",
    "    print(\"误差： \" + str(err))\n",
    "    print(\"相对误差率： \" + str(ff))\n",
    "    print(\"标准差： \" + str(d))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\项目\\\\廖煜胜-论文\\\\论文\\\\数据与程序\\\\datacollect\\\\test\\\\truevalue.txt\"\n",
    "value = getvalue(path)  # 真值\n",
    "measure = main2(29)\n",
    "getMae(measure, value)\n",
    "Mape(measure, value)\n",
    "Rmse(measure, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw4(title, measure, trueValue, label):\n",
    "    plt.figure(title)\n",
    "    x = [i for i in range(1, 13)]\n",
    "    plt.xlabel('轨迹序号', fontproperties='SimHei', fontsize=10)\n",
    "    plt.ylabel('轨迹长度（米）', fontproperties='SimHei', fontsize=10)\n",
    "    plt.title(\"计算值与真实值对比\")\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.15)  # 图边距t\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.xticks(x)\n",
    "    for i in range(1, len(x)):\n",
    "        d = ((measure[i] - trueValue[i]) / trueValue[i]) * 100\n",
    "        text = float(\"%.2f\" % d)\n",
    "        plt.text(x[i] - 0.4, measure[i] + 30, str(text) + \"%\", fontdict={'size': '10'})\n",
    "\n",
    "    plt.plot(x, measure, marker='*', linestyle='-.', label=label)  # 计算值\n",
    "    plt.plot(x, trueValue, marker='o', linestyle='-', label='真实值')  # 真值\n",
    "    plt.legend(loc='lower right')  # label生效\n",
    "    plt.savefig(\"D:\\\\fig\\\\picture\\\\\" + str(title) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw4(\"1d-cnn\", measure, value, \"1d-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
