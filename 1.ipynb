{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime \n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "##文件数据行为: x   y   z  time     ；表示一个坐标点的三个坐标分量和 采集时间 ，使用空格符分隔\n",
    "\n",
    "def pre(source, distance, diantance1):\n",
    "    f = open(source, \"r\")  # 源文件\n",
    "    fwrit = open(distance, \"a\")  # 卡2068\n",
    "    for s in f.readlines():\n",
    "        if len(s) == 1:\n",
    "            fwrit.write(s)\n",
    "        else:\n",
    "            s = s[:-1]\n",
    "            tem = s.split()\n",
    "            re = tem[1].split(':')[1] + \"\\t\" + tem[2].split(':')[1] + \"\\t\" + tem[3].split(':')[1] + \"\\t\" + tem[-2] + \"\\t\" + tem[-1] + \"\\n\"\n",
    "            # if tem[0] != \"2068\":\n",
    "            #     fwrit1.write(re)\n",
    "            # else:\n",
    "            if tem[0] == \"2068\":\n",
    "                fwrit.write(re)\n",
    "    f.close()\n",
    "    fwrit.close()\n",
    "\n",
    "\n",
    "def file_name(file_dir, target, target1):\n",
    "    path = [file_dir + '\\\\' + x for x in os.listdir(file_dir)]\n",
    "    for p in path:\n",
    "        if not os.path.isdir(p):\n",
    "            pre(p, target, target1)\n",
    "\n",
    "def split_data(splot):\n",
    "    \"\"\"\n",
    "    按照plot划分时间段\n",
    "    \"\"\"\n",
    "    state = \"D:\\\\fig\\\\data\\\\pre2068Static.txt\"\n",
    "    unrealize = \"D:\\\\fig\\\\data\\\\pre2068Unrealize.txt\"\n",
    "    Sactive = \"D:\\\\fig\\\\data\\\\pre2068Little.txt\"\n",
    "    Mactive = \"D:\\\\fig\\\\data\\\\pre2068LargeMove.txt\"\n",
    "    files = [state, unrealize, Sactive, Mactive]\n",
    "    mask = [1., 2., 3., 4.]\n",
    "    splotre = []\n",
    "    lable = [] \n",
    "    for index, file in enumerate(files):\n",
    "        f = open(file, \"r\")\n",
    "        mk = mask[index]\n",
    "\n",
    "        flag = False \n",
    "        start = ''\n",
    "        obj = [] \n",
    "        for s in f.readlines():\n",
    "            if len(s) <= 1:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                s = s[:-1]\n",
    "                seq = s.split(\"\\t\")\n",
    "                if flag == False :\n",
    "                    #本数据序列第一点的采集时间\n",
    "                    start = 0\n",
    "                    now = 0\n",
    "                    flag = True \n",
    "                # 当前点的采集时间\n",
    "                now = now + 1\n",
    "                subt = now - start \n",
    "                obj.append(np.asarray(seq[:3],dtype='float64'))\n",
    "            if subt > splot:\n",
    "                splotre.append(np.asarray(obj))\n",
    "                lable.append(mk)\n",
    "                obj.clear() \n",
    "                flag = False\n",
    "    splotre = np.asarray(splotre)\n",
    "    lable = np.asarray(lable)\n",
    "    return splotre, lable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大幅度运动 原始数据源\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\active\"\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068LargeMove.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preLargeMove.txt\"  # 其他卡的处理结果\n",
    "\n",
    "file_name(p, t, t1)\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\little\"  # 原始数据源\n",
    "\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Little.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preLittle.txt\"  # 其他卡的处理结果\n",
    "\n",
    "file_name(p, t, t1)\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\static\"  # 原始数据源\n",
    "\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Static.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preStatic.txt\"  # 其他卡的处理结果\n",
    "file_name(p, t, t1)\n",
    "# 无意识运动，如转身，手摆动\n",
    "p = \"E:\\\\datacollect\\\\trian\\\\unrealize\"  # 原始数据源\n",
    "# 数据预处理结果保存路径\n",
    "t = \"D:\\\\fig\\\\data\\\\pre2068Unrealize.txt\"  # 卡2068对应的数据，处理结果\n",
    "t1 = \"D:\\\\fig\\\\data\\\\preUnrealize.txt\"  # 其他卡的处理结果径\n",
    "file_name(p, t, t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        ...,\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ]],\n",
       "\n",
       "       [[ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        ...,\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ]],\n",
       "\n",
       "       [[ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        ...,\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ],\n",
       "        [ 4.80734,  0.89978,  1.5    ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 6.69377, -0.45626,  1.5    ],\n",
       "        [ 6.69377, -0.45626,  1.5    ],\n",
       "        [ 7.21234, -0.38367,  1.5    ],\n",
       "        ...,\n",
       "        [ 7.88736,  2.65041,  1.5    ],\n",
       "        [ 7.70676,  2.93816,  1.5    ],\n",
       "        [ 7.70676,  2.93816,  1.5    ]],\n",
       "\n",
       "       [[ 7.37501,  3.22528,  1.5    ],\n",
       "        [ 7.1112 ,  3.16778,  1.5    ],\n",
       "        [ 6.86056,  3.14418,  1.5    ],\n",
       "        ...,\n",
       "        [ 8.18929,  2.28952,  1.5    ],\n",
       "        [ 8.18482,  2.08379,  1.5    ],\n",
       "        [ 8.09285,  1.8695 ,  1.5    ]],\n",
       "\n",
       "       [[ 8.06092,  1.57082,  1.5    ],\n",
       "        [ 8.06064,  1.31173,  1.5    ],\n",
       "        [ 8.03174,  1.06668,  1.5    ],\n",
       "        ...,\n",
       "        [ 5.47525, -0.73263,  1.5    ],\n",
       "        [ 5.1933 , -0.66509,  1.5    ],\n",
       "        [ 4.95262, -0.64923,  1.5    ]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splotre, lable = split_data(19)\n",
    "splotre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division \n",
    "import os \n",
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision import transforms, utils\n",
    "class LocationDataset(Dataset):\n",
    "    def __init__(self, splotre, lable, transform = None):\n",
    "        self.splotre = splotre \n",
    "        self.lable = lable \n",
    "        self.transform = transform \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.splotre)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        splot = self.splotre[idx] \n",
    "        lable = self.lable[idx]\n",
    "        \n",
    "        sample = {'dataset':splot, 'lable':lable}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'splotre' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ead73e7f4f2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLocationDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplotre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'splotre' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = LocationDataset(splotre, lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 2953, 22022, 23551, 23625, 23305, 16113, 3397, 13243, 336, 8749, 24224, 3536, 23117, 183, 9764, 6022, 3237, 8980, 16899, 6931, 7505, 18218, 19398, 24182, 15664, 25778, 17549, 24821, 2533, 18409, 1956, 21476, 6227, 7146, 24578, 1997, 8743, 25496, 5699, 18960, 106, 20553, 8898, 20767, 25329, 20273, 26940, 27488, 23200, 472, 2053, 4499, 28320, 20796, 24588, 5753, 27957, 7842, 5199, 1957, 23025, 22329, 1374, 20887, 18971, 24123, 20209, 14335, 216, 22062, 20693, 26779, 19846, 17095, 24506, 443, 3718, 22480, 15727, 27444, 18060, 19927, 12483, 1532, 3679, 28612, 5385, 21588, 24382, 3471, 28223, 18189, 25662, 16377, 14240, 8358, 9561, 17646, 19366, 12052, 28620, 13025, 9887, 6655, 9585, 21894, 1328, 27761, 6850, 12974, 23957, 26532, 27415, 18615, 13572, 16678, 20373, 12852, 19986, 3238, 24004, 17510, 5403, 20012, 2908, 23674, 15002, 22332, 14206, 7686, 19843, 7256, 7036, 63, 13160, 1161, 12291, 14508, 5913, 6962, 25698, 15173, 6013, 17072, 21966, 14945, 3123, 17415, 26203, 24498, 6648, 14910, 20475, 23462, 13958, 12125, 9205, 6991, 17831, 1017, 23965, 3282, 22889, 9928, 18393, 3781, 21416, 4506, 5492, 8653, 7243, 8701, 20641, 24233, 21620, 3358, 15057, 640, 3045, 21019, 7246, 10999, 3129, 5835, 15964, 17993, 11997, 16716, 12015, 18080, 26636, 7570, 4678, 2238, 18153, 16877, 2190, 5586, 17503, 9736, 12684, 17974, 14271, 16947, 1244, 21236, 13881, 12235, 20931, 5485, 15160, 14279, 27802, 16391, 3387, 10656, 7942, 18768, 8419, 22534, 21881, 15097, 11479, 28309, 9284, 19645, 18718, 14191, 20634, 19161, 26673, 9016, 437, 2821, 26164, 507, 23077, 20696, 603, 7670, 17138, 18096, 20483, 867, 19693, 13832, 4355, 20162, 25989, 15814, 16989, 22765, 3464, 4379, 11144, 12294, 7390, 16839, 11184, 12508, 16475, 19089, 14892, 19324, 2214, 20626, 10181, 11889, 20181, 315, 14865, 22953, 21353, 25794, 27528, 12478, 23030, 23258, 14650, 22722, 16025, 27483, 2782, 15123, 24410, 20205, 4137, 24615, 15460, 24544, 16536, 24268, 2971, 19915, 3513, 19504, 25896, 9724, 13201, 26233, 4909, 18920, 19167, 9871, 10188, 15670, 15993, 9729, 497, 5181, 7297, 24154, 21116, 13027, 9238, 21084, 20997, 25513, 1285, 10240, 15185, 27967, 6018, 14935, 16834, 9599, 24229, 7928, 26463, 6230, 16436, 3227, 6971, 26224, 18894, 2489, 24839, 18154, 12939, 1774, 25064, 4468, 2856, 27606, 1337, 14724, 7127, 24796, 3213, 7247, 19667, 9730, 16288, 26222, 765, 21690, 23732, 27195, 5983, 171, 17904, 9952, 592, 23296, 19862, 25370, 14879, 6953, 22551, 12110, 16050, 8601, 23467, 12745, 15218, 23956, 13523, 10344, 5973, 21840, 16796, 13012, 12081, 7931, 25092, 19828, 7315, 1683, 15387, 3473, 20700, 21709, 27241, 22617, 17252, 1995, 23342, 18503, 8635, 13430, 13106, 20353, 2758, 3003, 13982, 12553, 9662, 25204, 22253, 16077, 13297, 20780, 15926, 14555, 16647, 12032, 14404, 10069, 2712, 4306, 7000, 24062, 6858, 4784, 16794, 5540, 11998, 17444, 26504, 2383, 18182, 8094, 6855, 13717, 7945, 2330, 13764, 2869, 11384, 24609, 8620, 18411, 16827, 2169, 16936, 594, 64, 14403, 20247, 21022, 21247, 6568, 7496, 4733, 7194, 12382, 19815, 6288, 13501, 5073, 16551, 18907, 21641, 15737, 8744, 25004, 5722, 21751, 16228, 13810, 13124, 18073, 24094, 23561, 379, 26736, 2895, 6357, 5954, 22289, 8017, 17600, 3112, 12923, 10569, 8987, 632, 8344, 24169, 27011, 6128, 6262, 24273, 26347, 10708, 7217, 16599, 4950, 8772, 13362, 6270, 9120, 24146, 25470, 25651, 6025, 2726, 8088, 25031, 6967, 28477, 898, 11809, 9045, 17237, 8074, 12143, 1812, 16901, 2912, 6281, 27692, 3119, 4956, 26354, 6606, 26384, 23659, 5317, 5589, 25912, 10645, 23090, 7394, 2939, 18473, 22863, 4675, 16005, 9536, 7511, 14589, 25076, 18864, 6600, 4241, 26068, 27872, 828, 1443, 5902, 13911, 18693, 2978, 24088, 3202, 9453, 21629, 4344, 2211, 13657, 4621, 27942, 24868, 20110, 13704, 19001, 23167, 6920, 5312, 3140, 1008, 19761, 17542, 1382, 22971, 25028, 23336, 27881, 24956, 9987, 19991, 17782, 27640, 11796, 13687, 24101, 2047, 1820, 9460, 3850, 2606, 22315, 9926, 17610, 5904, 8825, 15927, 1158, 16737, 27616, 16448, 23439, 11064, 1663, 18342, 3574, 5575, 12612, 28196, 14552, 7077, 12643, 9261, 1838, 26070, 4323, 5210, 27246, 26456, 6490, 24091, 9307, 18796, 2088, 13175, 15240, 16835, 4098, 27947, 1953, 7298, 16844, 17788, 1901, 4504, 10764, 4388, 2460, 28462, 15399, 2788, 18582, 16626, 9096, 25774, 13550, 1859, 28056, 7870, 14562, 8513, 26010, 11777, 14998, 18973, 2260, 14668, 24495, 11902, 15347, 19790, 15818, 9177, 4557, 450, 15969, 20712, 8528, 13424, 4312, 14731, 17110, 10657, 27384, 16730, 19123, 16740, 24600, 22835, 7720, 21915, 4722, 4898, 1486, 25582, 3081, 12997, 15582, 8833, 27909, 7944, 21584, 17602, 20464, 6047, 4830, 16022, 17343, 25828, 17810, 20317, 13471, 22092, 20621, 22280, 20075, 23017, 6124, 1003, 13586, 19822, 9469, 21428, 16697, 11028, 1870, 19388, 20697, 27800, 16061, 13060, 13045, 17336, 6952, 4487, 1252, 18989, 7484, 2747, 27116, 11137, 14575, 17707, 4872, 10956, 3310, 23415, 15909, 11455, 10867, 24404, 15617, 24869, 26196, 2003, 17013, 2367, 6577, 1099, 101, 5773, 3702, 24435, 9269, 21878, 6597, 3805, 18047, 1037, 27377, 12703, 8762, 14031, 2323, 8511, 28231, 5865, 25992, 16348, 24863, 12603, 18987, 1710, 7178, 23223, 28271, 19798, 4535, 12671, 492, 18078, 20956, 10552, 25395, 8918, 25193, 4712, 28572, 4467, 23830, 20829, 4434, 25026, 22076, 27562, 21768, 17982, 7266, 21727, 16637, 23149, 8726, 9465, 4658, 13519, 9692, 21060, 11341, 18893, 2887, 26552, 14756, 24918, 14352, 15128, 9852, 14096, 24053, 18500, 18102, 14530, 27822, 26235, 26547, 8872, 19755, 22652, 6268, 9723, 21948, 445, 2513, 2164, 27114, 8553, 8366, 5198, 14480, 10660, 19478, 5009, 23349, 8683, 3332, 27962, 21299, 6780, 6393, 14278, 11294, 17202, 22675, 12895, 27098, 21747, 18992, 13506, 8961, 596, 24444, 18767, 10045, 6505, 19987, 2305, 12404, 18604, 8770, 17637, 18869, 14272, 5424, 3588, 9163, 21920, 14856, 28619, 22368, 25500, 10961, 3972, 6114, 7744, 26856, 22773, 6420, 21275, 15051, 25239, 21006, 22595, 17866, 7071, 15851, 4748, 19917, 14520, 22720, 2871, 5379, 15405, 12836, 8042, 9258, 12645, 25880, 14220, 4463, 8426, 18230, 13210, 22070, 20828, 25363, 25345, 26052, 2387, 8141, 11013, 8908, 11159, 21707, 3579, 23646, 10084, 18249, 18603, 10808, 9130, 2979, 27189, 28609, 12458, 4686, 3374, 4953, 11613, 6647, 800, 14446, 11974, 12912, 11399, 9171, 2612, 13765, 21634, 23516, 27243, 26948, 26749, 3783, 15381, 15825, 1218, 61, 13122, 27102, 8670, 5595, 10055, 16603, 26134, 5588, 22101, 5616, 21426, 4280, 19500, 18271, 4424, 5353, 27903, 19132, 5369, 7099, 2649, 4275, 1793, 157, 21577, 12279, 10349, 18033, 11655, 11611, 23485, 12844, 18141, 4299, 14300, 22716, 2253, 7632, 20479, 1835, 3931, 24941, 8078, 19956, 10733, 4750, 899, 16891, 5625, 42, 5169, 540, 23004, 115, 25269, 24866, 6099, 249, 1671, 5932, 23124, 28568, 6618, 12651, 25822, 16545, 21102, 8265, 6902, 10717, 16102, 27917, 3888, 23380, 8054, 27657, 14905, 22869, 1866, 8298, 15357, 17396, 17205, 7212, 18050, 1614, 21805, 11512, 18227, 6290, 17877, 23237, 17840, 23171, 4804, 1366, 5140, 9006, 12029, 579, 20707, 13548, 14927, 766, 4370, 6797, 24508, 10724, 17981, 7299, 23716, 26404, 13781, 23320, 16964, 18875, 22668, 13819, 10200, 4283, 6616, 23603, 24982, 5770, 27580, 19255, 4634, 8371, 8019, 15815, 5135, 20937, 15021, 25699, 4890, 17312, 18426, 11930, 3092, 17884, 12230, 8990, 3055, 22053, 9275, 1948, 15588, 27908, 7822, 10362, 5000, 22175, 5642, 19380, 3569, 10828, 2060, 18024, 16110, 8504, 10898, 15622, 16848, 1319, 9581, 17918, 10348, 23201, 23855, 27705, 20751, 15484, 17150, 27211, 12189, 16002, 8103, 20154, 1096, 25947, 11315, 27004, 12144, 1523, 10187, 21787, 13913, 13320, 9574, 210, 15514, 26340, 14630, 2090, 13275, 3547, 24181, 27299, 4955, 6246, 7966, 23098, 15643, 22443, 24598, 16223, 3538, 25898, 9718, 21081, 19547, 18247, 16797, 27619, 4399, 2506, 17891, 932, 9717, 17294, 13653, 25895, 2436, 16963, 14973, 4341, 15498, 11891, 5313, 12906, 6103, 15805, 12717, 15340, 9137, 143, 16931, 12888, 3674, 24301, 24065, 5788, 20272, 22519, 28606, 22195, 28006, 2220, 16325, 22150, 19146, 23262, 10649, 20444, 931, 6700, 27374, 24537, 5360, 27621, 11244, 3508, 24271, 26489, 19867, 2919, 14033, 3733, 23538, 11166, 23099, 20880, 11948, 21179, 20395, 7273, 25502, 1259, 14578, 13458, 16376, 38, 7002, 9151, 7372, 6056, 26785, 8076, 5429, 7303, 4194, 8041, 4491, 3543, 23227, 13437, 5532, 14013, 12363, 13293, 4046, 1659, 2051, 23499, 18221, 9992, 7848, 22718, 10003, 4765, 25499, 4719, 28453, 9328, 5756, 24113, 664, 3258, 384, 4256, 1620, 13549, 6873, 20532, 24534, 9389, 9701, 8480, 2502, 27000, 4964, 3557, 22931, 27598, 16487, 16083, 28312, 3963, 1592, 25903, 19433, 8428, 7030, 21695, 15001, 15641, 7867, 18652, 15275, 25963, 15801, 16643, 9409, 3981, 7758, 26798, 8808, 15652, 23233, 2858, 23424, 27277, 22074, 936, 12931, 12971, 8578, 653, 20500, 13692, 19355, 13820, 9766, 11592, 4870, 28095, 8697, 8627, 19745, 19370, 1050, 28375, 5108, 6890, 15713, 1817, 1219, 13421, 15278, 18119, 26583, 6790, 19109, 24809, 25626, 10182, 26561, 25988, 5048, 14544, 28593, 13439, 18262, 1545, 3054, 10177, 8326, 10117, 5911, 10229, 4736, 25410, 2106, 10063, 10178, 4753, 22565, 3989, 8453, 20314, 9885, 19735, 3902, 7301, 27351, 26217, 23126, 3732, 8107, 6508, 18959, 12535, 24713, 19532, 20554, 23893, 321, 1056, 9341, 8136, 19408, 14304, 6259, 25501, 24965, 5406, 7571, 25748, 8089, 27545, 13490, 27884, 6801, 16841, 24960, 1427, 24463, 18775, 2236, 21077, 11276, 4000, 11743, 19072, 16080, 9774, 2063, 13792, 27066, 1286, 4011, 20752, 13863, 21209, 3083, 23287, 4438, 19384, 12828, 11607, 18419, 15934, 6336, 25661, 12595, 27054, 3071, 11994, 4599, 2968, 918, 11925, 18874, 6504, 11547, 14291, 19906, 8896, 3562, 22824, 15879, 22367, 16074, 15552, 26365, 13932, 7352, 10550, 24285, 16340, 9617, 18076, 16446, 12348, 13627, 8497, 24781, 5738, 24464, 2456, 10851, 15597, 19679, 11405, 15811, 24746, 7421, 13229, 7107, 10248, 5811, 70, 15574, 5096, 18764, 19544, 21806, 16157, 19163, 6185, 24743, 298, 4935, 18308, 26313, 5378, 21415, 23151, 755, 4951, 11555, 26699, 24095, 16601, 24913, 20564, 6278, 10085, 14794, 14395, 20122, 4938, 22618, 12059, 16128, 6924, 6171, 9113, 15126, 15646, 18941, 9354, 24078, 27720, 20622, 18368, 23414, 26774, 3320, 21233, 7023, 12161, 8741, 19740, 20092, 13682, 392, 20671, 5513, 7704, 18548, 8191, 10753, 18755, 18623, 18334, 14808, 18901, 27140, 17059, 22724, 16369, 311, 13335, 25238, 1005, 13976, 2762, 14309, 15472, 12408, 3673, 18555, 17479, 11036, 6109, 17984, 6378, 14590, 4799, 9810, 12141, 24100, 9738, 10681, 15850, 10560, 16292, 25478, 16169, 25923, 25645, 14730, 1253, 26822, 11038, 25419, 22950, 18286, 6226, 23574, 28148, 15569, 3391, 5996, 27627, 14055, 28570, 27309, 26878, 16607, 25277, 10618, 25827, 24583, 8278, 18049, 10197, 20640, 23299, 22701, 7784, 2715, 10856, 21542, 14803, 22167, 1634, 1551, 18228, 17096, 17538, 10285, 22216, 15027, 23199, 21829, 27737, 10346, 1972, 1095, 2112, 10853, 9141, 4431, 1819, 2119, 17663, 9225, 6917, 11412, 7370, 27605, 26263, 6751, 8799, 22231, 10012, 12500, 19588, 11978, 14503, 9173, 23717, 11584, 5413, 19839, 27954, 4611, 5749, 24532, 19903, 21423, 1667, 12896, 15109, 26493, 4255, 10809, 14490, 5352, 7507, 9306, 15181, 3826, 1071, 24225, 19710, 16191, 19, 11924, 27446, 21598, 21328, 20498, 1583, 20929, 11850, 20681, 24466, 3560, 2603, 7591, 24800, 7509, 13961, 21669, 28052, 21165, 4651, 21252, 6514, 14491, 25804, 14109, 21127, 209, 14851, 21210, 10899, 12306, 448, 24857, 15127, 7302, 9509, 11296, 7104, 2488, 4589, 14519, 1887, 28014, 8734, 18835, 13722, 5024, 11794, 25206, 22688, 14605, 11251, 10893, 1028, 18374, 13930, 8260, 17562, 14937, 24057, 21677, 19993, 25856, 6689, 215, 18447, 3814, 15441, 774, 7783, 7050, 14290, 10960, 6135, 13484, 28222, 9236, 2089, 18296, 1499, 26468, 10286, 14594, 16639, 9166, 8341, 28023, 18344, 10393, 16097, 147, 18791, 11697, 19954, 9803, 6513, 29, 26831, 25816, 12023, 257, 4545, 22553, 20157, 16804, 27603, 12011, 11927, 7607, 16281, 18111, 27084, 10694, 15933, 22309, 3847, 11277, 12218, 19415, 7396, 21528, 27236, 1446, 5720, 15335, 6837, 17752, 24975, 2928, 19428, 11598, 8047, 12549, 27842, 3623, 13476, 10291, 15217, 26421, 14038, 4867, 19439, 3157, 3799, 12186, 5777, 752, 27503, 25642, 22658, 4818, 15976, 14895, 19706, 20099, 15327, 2868, 22130, 13050, 20354, 12512, 16878, 15302, 9438, 19444, 911, 6554, 27508, 26833, 6126, 4655, 10426, 23510, 13305, 3831, 10164, 11292, 735, 6328, 1346, 28458, 13299, 7079, 6977, 5583, 8579, 9598, 10356, 26502, 11898, 3368, 33, 26396, 23395, 24879, 6903, 26821, 345, 24507, 7752, 19672, 13851, 4697, 4977, 17681, 25024, 3933, 4446, 7210, 20007, 3497, 24217, 6195, 974, 26951, 21621, 7791, 20628, 231, 835, 3868, 5795, 698, 5683, 1339, 10476, 24829, 7962, 21659, 18547, 10487, 8447, 618, 3223, 8030, 15691, 1650, 15389, 6279, 17478, 4223, 25953, 1018, 12290, 28029, 13398, 15989, 10672, 9895, 7494, 18583, 7479, 8441, 15464, 9950, 12545, 9292, 6745, 12163, 5118, 1199, 3399, 13115, 7724, 10608, 13161, 12327, 14709, 22502, 502, 5810, 25682, 7538, 13140, 16460, 14334, 15762, 3912, 27837, 9669, 13791, 14748, 6423, 3220, 2581, 5068, 24519, 17271, 10639, 8999, 17977, 28134, 23143, 4963, 10300, 26122, 9880, 24626, 12620, 20335, 13353, 11259, 14913, 9321, 24445, 5580, 9086, 15252, 20789, 9953, 12324, 6784, 11404, 17402, 7304, 22879, 27491, 15705, 14092, 623, 2605, 2906, 14613, 27857, 5690, 26663, 19325, 19642, 20800, 12530, 2427, 18624, 18058, 20954, 26401, 16610, 21260, 17348, 3595, 3089, 10428, 25829, 16979, 18298, 8015, 5842, 3511, 12827, 27135, 12797, 7995, 1156, 23989, 9294, 9627, 27221, 13079, 3456, 28071, 1066, 2004, 25060, 23394, 20934, 17088, 10452, 27160, 19390, 3573, 24492, 1080, 12873, 14499, 5553, 12226, 13198, 7610, 15515, 13245, 3751, 22981, 2344, 1966, 12882, 505, 24630, 3073, 11980, 22490, 20909, 11111, 26892, 9395, 13555, 24489, 7222, 21389, 15517, 21763, 26357, 2498, 10908, 19157, 16533, 5933, 10124, 15513, 19464, 22254, 148, 28502, 17864, 6852, 4076, 16407, 5845, 2598, 3704, 17405, 821, 18220, 23753, 10128, 26295, 4897, 4147, 8445, 710, 1632, 13340, 14771, 260, 8361, 8165, 1517, 18361, 14394, 11748, 19542, 203, 16630, 857, 19768, 9169, 12953, 24024, 11129, 18684, 14, 3416, 25860, 23314, 3907, 21944, 13780, 6921, 21263, 1760, 19391, 9396, 28341, 13342, 6080, 22228, 10328, 24035, 18034, 12753, 3469, 6112, 3975, 20645, 21586, 7750, 22877, 21002, 8580, 23159, 27044, 11788, 24375, 23400, 17210, 26175, 21822, 2327, 12668, 9032, 10472, 3012, 6424, 6052, 19359, 1085, 4562, 25617, 27595, 5109, 21779, 7348, 11451, 5715, 20224, 28118, 779, 26927, 17162, 4493, 15073, 19342, 6137, 7593, 6875, 20227, 21031, 13971, 13386, 27925, 14417, 16558, 7668, 15862, 26324, 25405, 1303, 846, 27136, 22306, 11089, 28431, 12445, 20572, 22047, 14098, 12683, 20037, 6548, 22223, 24872, 19352, 3074, 25535, 15019, 9202, 9213, 23759, 164, 26209, 5310, 11854, 2487, 6586, 6722, 25978, 3160, 5402, 16897, 25037, 17225, 12782, 2412, 20364, 15333, 17921, 21877, 14843, 2424, 16823, 8052, 11059, 26982, 7986, 5408, 3905, 3881, 7186, 10854, 22738, 18490, 9963, 22088, 16190, 27099, 6084, 25189, 23948, 9516, 7005, 8558, 16505, 1574, 16415, 7918, 2563, 27258, 13802, 3443, 25114, 21499, 15559, 25353, 7660, 11108, 2601, 6098, 25023, 7548, 72, 11364, 3921, 1109, 4205, 13790, 20723, 3876, 3489, 303, 21701, 2915, 18663, 19278, 426, 22743, 9933, 13389, 4820, 15266, 10239, 25361, 19291, 25731, 7643, 25850, 17331, 28461, 16998, 13522, 1107, 18375, 7233, 21653, 13286, 5487, 13071, 26849, 3377, 11471, 23217, 20566, 10267, 22610, 11531, 5259, 16503, 12574, 4944, 24712, 17550, 11096, 13102, 1907, 12871, 27152, 2140, 20088, 20729, 16006, 20852, 18728, 26628, 21483, 2316, 11334, 21361, 4183, 14157, 24592, 16608, 21818, 24254, 8717, 12601, 12835, 24032, 19443, 8596, 1323, 23607, 23996, 21750, 6511, 13379, 17075, 23097, 22318, 15434, 26190, 8841, 7567, 17058, 22511, 12924, 25333, 14207, 11537, 2597, 8778, 189, 15781, 2273, 25929, 6886, 27223, 9371, 21365, 16478, 13684, 4089, 22602, 18068, 10921, 23359, 17037, 13139, 15366, 14979, 14126, 13584, 12427, 19034, 24680, 22146, 9010, 12821, 1584, 24168, 16192, 12441, 10778, 10064, 20387, 2390, 9888, 22507, 3678, 4554, 17715, 22650, 16018, 14482, 11935, 16962, 28120, 48, 25723, 27251, 27858, 21607, 5663, 15269, 27742, 24738, 17043, 15533, 16242, 6843, 24130, 3687, 10243, 4756, 9281, 23592, 15941, 1375, 5725, 11022, 16455, 23702, 11857, 25871, 25271, 5453, 2630, 8779, 22876, 24442, 11117, 24071, 24674, 21132, 7641, 11540, 4074, 2279, 18277, 2347, 24920, 7398, 23600, 12774, 7211, 2336, 2175, 2803, 14710, 15281, 21696, 10110, 21453, 9579, 25647, 16836, 23852, 24594, 10844, 24486, 7868, 24408, 23731, 16485, 13569, 50, 13931, 3655, 3472, 705, 5728, 11327, 5990, 154, 26941, 9270, 288, 17717, 7331, 3519, 4762, 27974, 24994, 20881, 18585, 15510, 2246, 26066, 804, 16586, 16360, 25472, 11164, 18854, 14876, 16935, 25192, 15171, 7113, 17039, 22909, 4824, 23464, 17828, 23709, 7545, 23062, 23988, 8044, 10280, 20408, 27395, 8722, 24952, 24241, 13451, 6002, 25483, 3136, 3626, 6276, 23856, 20173, 23777, 12192, 20870, 24561, 7772, 27898, 9629, 24084, 14162, 8049, 20090, 14382, 28590, 4747, 9771, 13216, 10347, 11664, 13778, 21044, 24596, 7436, 13664, 23327, 21057, 26100, 24349, 20194, 12332, 27186, 3144, 9678, 489, 23454, 21601, 14736, 7470, 26726, 25666, 14411, 10086, 19628, 25170, 5167, 54, 14728, 23461, 11359, 17001, 10324, 28130, 12410, 1694, 22888, 22750, 4352, 27949, 571, 12181, 9494, 25517, 28038, 7338, 12884, 8876, 23689, 20620, 6212, 13265, 11714, 20998, 13259, 28417, 18878, 25141, 818, 11340, 2554, 6011, 4680, 18333, 12485, 13309, 14647, 18939, 5645, 19078, 23020, 18528, 4808, 19951, 13162, 26285, 9840, 26936, 5813, 24812, 20612, 19971, 18015, 8083, 28086, 8259, 19374, 19338, 14494, 4517, 13391, 20001, 2410, 11521, 7881, 8055, 17389, 17533, 2017, 5038, 9567, 1946, 16107, 28182, 19809, 7800, 19627, 26700, 5833, 4162, 27900, 28259, 16787, 25094, 25759, 5750, 27403, 4653, 17941, 15580, 21137, 1436, 17955, 9896, 3794, 9455, 2555, 10827, 22411, 23229, 14550, 22154, 24399, 26731, 28026, 7885, 4741, 26528, 9414, 4426, 9800, 17907, 6887, 20120, 8405, 485, 22202, 22108, 21713, 6125, 15137, 6100, 15138, 28066, 13136, 25272, 21871, 7369, 4269, 25983, 18980, 13681, 14815, 21398, 15497, 23011, 4125, 7124, 7869, 12733, 27694, 20204, 28140, 13276, 20020, 21618, 5634, 25012, 7562, 10041, 14184, 7540, 7419, 26873, 25249, 23119, 11314, 14991, 5816, 12350, 17596, 5489, 4252, 23450, 25520, 23155, 6384, 27105, 27419, 21857, 2525, 15414, 25366, 6476, 23426, 25260, 10009, 28163, 4063, 16341, 25397, 26234, 2272, 15978, 20686, 22560, 7633, 10427, 22305, 16186, 11104, 12874, 28472, 23468, 17621, 6462, 1352, 3475, 23294, 28415, 17012, 25744, 21550, 18237, 3658, 1031, 15200, 26098, 20863, 26478, 18713, 16682, 10235, 27997, 6553, 10680, 14345, 17412, 357, 28261, 24758, 1301, 13370, 4922, 22009, 8169, 28452, 18787, 15576, 22504, 21735, 16232, 11628, 18646, 12618, 24247, 21313, 19533, 9001, 6330, 6451, 25893, 12439, 14825, 21785, 17369, 22043, 17157, 16650, 14908, 3345, 17870, 8587, 2493, 8605, 25160, 12541, 14531, 12988, 18084, 27356, 27492, 16324, 3153, 12996, 24947, 4558, 13206, 13619, 935, 11427, 22677, 10522, 5568, 27340, 14326, 10910, 8418, 5153, 9828, 3528, 695, 27943, 6398, 15007, 23224, 6426, 15980, 24485, 24571, 2699, 6077, 20813, 18946, 12097, 14318, 21858, 3717, 18465, 11439, 27112, 10822, 3096, 19668, 15672, 16573, 22445, 13230, 17241, 18949, 26539, 26300, 13636, 1372, 21940, 26165, 9633, 3250, 1699, 15003, 27383, 23429, 2740, 21122, 18165, 13702, 25964, 15924, 14189, 9594, 17135, 23235, 23685, 21946, 5201, 1170, 24791, 15872, 6633, 26055, 8930, 2123, 16339, 27191, 19413, 21804, 12164, 6223, 13441, 16510, 1965, 23894, 26807, 15823, 27970, 10018, 17989, 28581, 5999, 3659, 11659, 3121, 5969, 19420, 26756, 8690, 22916, 278, 9108, 3818, 17091, 18407, 18395, 17469, 18420, 28598, 11121, 27224, 26803, 13155, 23335, 27090, 26091, 25385, 11928, 23820, 9625, 25910, 18025, 688, 4310, 3189, 12264, 22072, 4640, 24867, 9715, 19887, 6492, 11852, 21990, 24021, 19859, 26823, 19607, 17266, 28439, 6060, 22308, 27096, 14635, 5294, 17337, 9558, 5664, 13658, 27410]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 14008 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-3d3832057120>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-978e998ec31a>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0msplot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplotre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mlable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'dataset'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lable'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlable\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 14008 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "class   ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        dataset, lable = sample['dataset'], sample['lable'] \n",
    "        dataset = np.transpose(dataset)\n",
    "        return {\n",
    "            'dataset': torch.from_numpy(dataset),\n",
    "            'lable': lable\n",
    "        }\n",
    "dataset = LocationDataset(splotre, lable, transform=transforms.Compose([ToTensor()]))\n",
    "index = list(range(len(dataset)))\n",
    "np.random.shuffle(index)\n",
    "print(index)\n",
    "dataset = dataset[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 25000\n",
    "loader_train = DataLoader(splotre[:NUM_TRAIN+1000], batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "loader_val = DataLoader(splotre[:NUM_TRAIN+1000], batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, NUM_TRAIN+1000)))\n",
    "loader_test = loader_test = DataLoader(splotre[NUM_TRAIN+1000:], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F  # useful stateless functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_1 = 32 \n",
    "channel_2 = 16\n",
    "learning_rate = 1e-4\n",
    "model = None \n",
    "optimizer = None \n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv1d(20, 100, 1, stride = 1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(channel_2*20, 4)\n",
    ")\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9, nesterov = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "file = pd.read_csv('D:\\\\fig\\\\data\\\\pre2068LargeMove.txt', sep = '\\t')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
